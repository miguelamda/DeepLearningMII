{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/miguelamda/DL/blob/master/5.%20Redes%20Convolucionales/Practica5.1.%20Introducci%C3%B3n%20CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXqj0y6FWPEx"
      },
      "source": [
        "# PRÁCTICA 5.1. INTRODUCCIÓN A LAS REDES CONVOLUCIONALES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "collapsed": true,
        "id": "cd_625grWPEx",
        "outputId": "599817cd-f086-4e63-c7ef-812d99eecd0e"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms.v2 as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "fRo9rPp5WPEy"
      },
      "source": [
        "Vamos a comenzar mostrando una **Red Convolucional** muy simple para abordar el problema de clasificación MNIST que ya analizamos anteriormente. Con lo que hemos visto hasta ahora no resultará tan extraño, y más adelante detallaremos cada una de las capas que lo componen describiendo la funcionalidad que juegan en la red global. Veremos que, aunque la red convolucional que construiremos de forma directa es muy simple, supera el rendimiento de la red clásica que creamos en el notebook de la práctica 3.2.\n",
        "\n",
        "Si quieres leer una introducción (no matemática) de cómo y porqué funcionan las redes convolucionales puedes mirar [este magnífico blog de Ujjwal Karn](https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets).\n",
        "\n",
        "![](https://github.com/miguelamda/DL/blob/master/5.%20Redes%20Convolucionales/imgs/CNN.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "bExYOHpmWPEy"
      },
      "source": [
        "## 1. Construyendo una CNN\n",
        "\n",
        "Como se puede observar en el siguiente código, la red convolucional que vamos a usar está formada esencialmente por dos capas convoluciones bidimensionales (`Conv2d`) seguidas de dos capas max_pooling (`MaxPool2d`). \n",
        "\n",
        "A diferencia de `nn.Linear`, que opera sobre vectores aplanados, `nn.Conv2d` opera sobre tensores 2D (imágenes), preservando su estructura espacial. Por tanto, el valor que recibe en sus argumentos cambia, siendo `nn.Conv2d(in_channels,out_channels,kernel_size,stride,padding,padding_mode)`:\n",
        "* `in_channels`: canales de entrada. Por ejemplo, en imágenes en escala de grises sería 1, en imágenes a color RGB serían 3.\n",
        "* `out_channels`: canales de salida. Corresponde al número de mapas de activación de salida, es decir, el número de neuronas en la capa convolucional (cada neurona aplica la convolución con su kernel y genera un mapa de activación de salida).\n",
        "* `kernel_size`: tamaño del filtro convolucional (o kernel). Puede ser un entero $n$, dando lugar a un kernel $nxn$, o una tupla que indique otra forma $(m,n)$\n",
        "* `stride`: desplazamiento o stride aplicado en la convolución. Por defecto, 1.\n",
        "* `padding` y `padding_mode`: número de píxeles a extender la imagen de entrada mediante padding, según el método padding_mode (por defecto, con ceros).\n",
        "* Ver más parámetros [en la documentación](https://docs.pytorch.org/docs/stable/generated/torch.nn.Conv2d.html)\n",
        "\n",
        "Para `nn.MaxPool2d` tan solo debemos indicar el tamaño del kernel (igual que en `Conv2d`) y el stride.\n",
        "\n",
        "**Ejercicio:** Dada la definición de red convolucional siguiente, haz una lista de número de neuronas y tamaño de kernel en cada capa, en la celda siguiente:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 644
        },
        "id": "e8TkTX4zWPEy",
        "outputId": "e08dd12e-e8f5-4ddd-b00c-35868ab2db0e"
      },
      "outputs": [],
      "source": [
        "CNN = nn.Sequential(\n",
        "        nn.Conv2d(1, 32, kernel_size=3),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2), \n",
        "        nn.Conv2d(32, 64, kernel_size=3),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Escribe aquí tu solución:\n",
        "* capa 1\n",
        "* capa 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Solución:\n",
        "* Capa 1: convolución de 3x3, de 32 neuronas\n",
        "* Capa 2: convolución de 3x3, de 64 neuronas\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ahora veamos qué forma tiene esta red convolucional:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (1): ReLU()\n",
            "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (4): ReLU()\n",
            "  (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            ")\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "=================================================================\n",
              "Layer (type:depth-idx)                   Param #\n",
              "=================================================================\n",
              "├─Conv2d: 1-1                            320\n",
              "├─ReLU: 1-2                              --\n",
              "├─MaxPool2d: 1-3                         --\n",
              "├─Conv2d: 1-4                            18,496\n",
              "├─ReLU: 1-5                              --\n",
              "├─MaxPool2d: 1-6                         --\n",
              "=================================================================\n",
              "Total params: 18,816\n",
              "Trainable params: 18,816\n",
              "Non-trainable params: 0\n",
              "================================================================="
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torchsummary import summary\n",
        "print(CNN)\n",
        "summary(CNN,verbose=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Podemos ver las capas que hemos introducido, y el número de parámetros en cada una. Pero no podemos ver información de la forma que tienen los tensores que genera cada capa. Y es que la convolución en sí no necesita saber la forma del tensor de entrada, ya que aplicará la convolución a toda la imagen de entrada independientemente de su tamaño. Eso sí, el tamaño del tensor de salida (mapa de activación) dependerá del tamaño de entrada. \n",
        "\n",
        "Lo que hemos definido ha sido solo la parte convolucional. Para poder hacer clasificación multiclase (para MNIST), debemos usar una o varias capas donde hacer combinación lineal y finalmente aplicar *softmax* para inferir la clase final. \n",
        "\n",
        "**Ejercicio**: Como en el clasificador necesitaremos incluir una primera capa lineal, ¿cuál es el número de características que tendría de entrada? Recuerda que para definir dicha capa, `nn.Linear(in_features,out_features`, ¿cuánto es `in_features`? Puedes usar la siguiente fórmula para calcular el tamaño de salida $(W_{out},H_{out})$ de una operación convolucional aplicada a una entrada $(W_{in},H_{in})$ con un kernel de tamaño $(K_w,K_h)$, padding $P$ y stride $S$:\n",
        "\n",
        "$W_{out} = \\left\\lfloor \\frac{W_{in} - K_w + 2P}{S} \\right\\rfloor + 1$       \n",
        "\n",
        "$H_{out} = \\left\\lfloor \\frac{H_{in} - K_h + 2P}{S} \\right\\rfloor + 1$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Por simplicidad puedes asumir que la imagen de entrada es cuadrada y los kernels también. Es decir, la altura es igual a la anchura, por lo que solo hay que calcular $W$, ya que $H$ es igual.\n",
        "\n",
        "*Tu solución:*\n",
        "\n",
        "* Salida primera capa convolucional: \n",
        "* Salida primera capa MaxPool: \n",
        "* Salida segunda capa convolucional: \n",
        "* Salida segunda capa MaxPool: \n",
        "* Número de características total al final:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Solución:\n",
        "\n",
        "Podemos simplificar el cálculo porque las imágenes de entrada son cuadradas ($W_{in}$ = $H_{in}$) y los kernels son cuadrados ($K_w=K_h$, concretamente, son de 3x3).:\n",
        "* Salida primera capa convolucional: W_out = (28-3+2*0)/1+1 = 26\n",
        "* Salida primera capa MaxPool: 26/2 = 13\n",
        "* Salida segunda capa convolucional: W_out = (13-3+2*0)/1+1 = 11\n",
        "* Salida segunda capa MaxPool: 21/2 = 5\n",
        "* Número de características total al final: $5*5*64 = 1600$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Aunque normalmente estos cálculos se hacen mano según la fórmula descrita, la función `summary` puede servirnos de ayuda para automatizar este proceso. Le podemos pasar como argumento una tupla que defina el shape de entrada a la red. Los otros dos argumentos, verbose y device, los discutiremos más adelante."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "├─Conv2d: 1-1                            [-1, 32, 26, 26]          320\n",
              "├─ReLU: 1-2                              [-1, 32, 26, 26]          --\n",
              "├─MaxPool2d: 1-3                         [-1, 32, 13, 13]          --\n",
              "├─Conv2d: 1-4                            [-1, 64, 11, 11]          18,496\n",
              "├─ReLU: 1-5                              [-1, 64, 11, 11]          --\n",
              "├─MaxPool2d: 1-6                         [-1, 64, 5, 5]            --\n",
              "==========================================================================================\n",
              "Total params: 18,816\n",
              "Trainable params: 18,816\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 2.42\n",
              "==========================================================================================\n",
              "Input size (MB): 0.00\n",
              "Forward/backward pass size (MB): 0.22\n",
              "Params size (MB): 0.07\n",
              "Estimated Total Size (MB): 0.30\n",
              "=========================================================================================="
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "summary(CNN, (1,28,28), verbose=0, device='cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "En PyTorch, una red convolucional toma como dato de entrada un tensor de la forma `(image_channels, image_height, image_width)`. En este caso, para ajustarse a las características de las imágenes de MNIST, será `(1, 28, 28)`, ya que usaremos un solo canal (gris) en las imágenes.\n",
        "\n",
        "Cada capa de tipo `Conv2d()` y `MaxPool2d()` dan como salida un tensor 3D de forma `(channels, height, width)`. Tanto la anchura como altura del tensor tienden a disminuir a medida que avanzamos en la red. El -1 que ves al principio corresponde a la dimensión del batch. Y es que las capas están diseñadas para recibir batches como entrada, no datos únicos.\n",
        "\n",
        "A continuación, hemos de pasar la salida de la última capa anterior (de tamaño `(64, 5, 5)`) a una red lineal clasificadora similar a las que ya hemos visto en ejemplos anteriores. Como estas capas procesan vectores, que son 1D, y la entrada es un tensor 3D, hemos de aplanar el tensor por medio de la capa `Flatten()`, que también proporciona PyTorch:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "clasificador = nn.Sequential(\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(64 * 5 * 5, 128),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(128, 10)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finalmente podemos juntar la parte convolucional con la parte del clasificador en un único modelo. Podemos usar de nuevo `nn.Sequential` como hasta ahora. Esta vez vamos a usar de una forma distinta, mediante un diccionario ordenado, de esta forma le podemos dar un nombre a cada bloque."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (Bloque convolucional): Sequential(\n",
            "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (4): ReLU()\n",
            "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (Clasificador): Sequential(\n",
            "    (0): Flatten(start_dim=1, end_dim=-1)\n",
            "    (1): Linear(in_features=1600, out_features=128, bias=True)\n",
            "    (2): ReLU()\n",
            "    (3): Linear(in_features=128, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "├─Sequential: 1-1                        [-1, 64, 5, 5]            --\n",
              "|    └─Conv2d: 2-1                       [-1, 32, 26, 26]          320\n",
              "|    └─ReLU: 2-2                         [-1, 32, 26, 26]          --\n",
              "|    └─MaxPool2d: 2-3                    [-1, 32, 13, 13]          --\n",
              "|    └─Conv2d: 2-4                       [-1, 64, 11, 11]          18,496\n",
              "|    └─ReLU: 2-5                         [-1, 64, 11, 11]          --\n",
              "|    └─MaxPool2d: 2-6                    [-1, 64, 5, 5]            --\n",
              "├─Sequential: 1-2                        [-1, 10]                  --\n",
              "|    └─Flatten: 2-7                      [-1, 1600]                --\n",
              "|    └─Linear: 2-8                       [-1, 128]                 204,928\n",
              "|    └─ReLU: 2-9                         [-1, 128]                 --\n",
              "|    └─Linear: 2-10                      [-1, 10]                  1,290\n",
              "==========================================================================================\n",
              "Total params: 225,034\n",
              "Trainable params: 225,034\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 2.86\n",
              "==========================================================================================\n",
              "Input size (MB): 0.00\n",
              "Forward/backward pass size (MB): 0.23\n",
              "Params size (MB): 0.86\n",
              "Estimated Total Size (MB): 1.09\n",
              "=========================================================================================="
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from collections import OrderedDict\n",
        "\n",
        "model = nn.Sequential(\n",
        "    OrderedDict([\n",
        "        (\"Bloque convolucional\",CNN),\n",
        "        (\"Clasificador\",clasificador)\n",
        "    ]))\n",
        "\n",
        "print(model)\n",
        "summary(model, (1,28,28), verbose=0, device='cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2md9W0ONWPEy"
      },
      "source": [
        "Como el objetivo es calcular una clasificación en 10 clases, la última capa es una capa densa con 10 unidades. Como vimos en la práctica 3.2, no añadimos `softmax` ya que en PyTorch no es necesario al estar incluido dentro de la función de pérdida."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbBI0lt7WPEy"
      },
      "source": [
        "## 2. Carga de datos y entrenamiento\n",
        "\n",
        "Una vez definida la red, realizamos el entrenamiento de forma similar a como hicimos en el modelo simple de MNIST:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIec-or9WPEy",
        "outputId": "eec55d97-fe07-4622-d074-83a8113ee7a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9912422/9912422 [00:01<00:00, 7411338.42it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 294739.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 2773887.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 1031821.96it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose([transforms.PILToTensor(), transforms.ToDtype(torch.float32, scale=True)])\n",
        "\n",
        "# Descargar y cargar los datos de entrenamiento. Podemos pasarle el transformador a la hora de cargar el dataset\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Descargar y cargar los datos de prueba\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Y preparamos el resto de elementos para entrenar al modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "def accuracy(out, yb):\n",
        "    preds = torch.argmax(out, dim=1)  \n",
        "    return (preds == yb).float().mean().item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Train Loss: 0.1714, Val Accuracy: 0.98\n",
            "Epoch [2/5], Train Loss: 0.0505, Val Accuracy: 0.99\n",
            "Epoch [3/5], Train Loss: 0.0352, Val Accuracy: 0.99\n",
            "Epoch [4/5], Train Loss: 0.0254, Val Accuracy: 0.99\n",
            "Epoch [5/5], Train Loss: 0.0200, Val Accuracy: 0.99\n",
            "CPU times: user 9min 15s, sys: 5.68 s, total: 9min 20s\n",
            "Wall time: 1min 13s\n"
          ]
        }
      ],
      "source": [
        "%%time \n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 5\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train() # Poner el modelo en modo de entrenamiento\n",
        "    loss_acum = 0\n",
        "    for x, y in train_loader:        \n",
        "        # Forward pass\n",
        "        outputs = model(x)\n",
        "        loss = criterion(outputs, y)\n",
        "        \n",
        "        # Backward y optimizar\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        loss_acum += loss.item()\n",
        "    \n",
        "    train_loss = loss_acum / len(train_loader)\n",
        "    \n",
        "    # Evaluar el modelo en datos de prueba para obtener la precisión\n",
        "    model.eval() # Poner el modelo en modo de evaluación        \n",
        "    accu_acum = 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in test_loader:\n",
        "            outputs = model(x)\n",
        "            accu_acum += accuracy(outputs,y)            \n",
        "\n",
        "    accu = accu_acum / len(test_loader)\n",
        "    \n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Val Accuracy: {accu:.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Ejercicio opcional**: modifica el código anterior para reportar también la pérdida sobre el conjunto de validación."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UApnS4RkWPEz"
      },
      "source": [
        "Podemos ver que alcanzamos un accuracy del 99%, superando al modelo básico que vimos en la práctica 3.2. Sin embargo, el entrenamiento ha tardado algo más de tiempo, ¿podemos acelerarlo?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Aceleración con GPUs\n",
        "\n",
        "Según tu CPU, el bucle de entrenamiento anterior pudo haber tardado más o menos, pero seguro que ha durado uno o más minutos. Y es que, una CPU no es el dispositivo más eficiente para ser usado en el entrenamiento de redes neuronales. La CPU está diseñada para realizar cómputo con instrucciones muy complejas, pero con un nivel de paralelismo limitado (¿cuántos núcleos tiene tu CPU?). En cambio, una **tarjeta gráfica (GPU)** sí que provee la potencia computacional para acelerar los cálculos requeridos. Estamos hablando, principalmente, de **multiplicaciones de matrices** (como la que hicimos en la práctica anterior), y esta operación se puede *paralelizar* muy bien (piensa en calcular, en paralelo, el valor de cada elemento de salida). Una GPU provee de miles de núcleos que pueden, fácilmente, repartirse la carga de trabajo a través de su memoria. Si tienes una GPU de *NVIDIA*, podrás hacer estos cálculos con **CUDA**. Si tienes una GPU de *AMD*, con **ROCm**. Hay otros dispositivos, como las *TPUs* de Google, pero no las usaremos en esta asignatura. Si tienes acceso a una TPU, puedes configurarla también con PyTorch, simplemente busca la ayuda en el manual.\n",
        "\n",
        "Esta parte de la práctica podrás ejecutarla sin problema una vez estés en un entorno con una GPU (bien sea en local o en la nube). En la siguiente celda ejecutaremos la instrucción que nos muestra las GPUs disponibles en el sistema: `nvidia-smi`. Éste es un programa que se instala junto al driver de CUDA, la plataforma para cálculo paralelo de NVIDIA. La exclamación al comienzo indica que el código no es Python, sino una instrucción a ejecutar en el sistema (p.ej. en la terminal)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fri Oct 17 16:20:57 2025       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 530.30.02              Driver Version: 530.30.02    CUDA Version: 12.1     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                  Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA GeForce RTX 2080         Off| 00000000:01:00.0 Off |                  N/A |\n",
            "|  0%   47C    P8                3W / 265W|   1044MiB /  8192MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "|   1  NVIDIA GeForce RTX 3090         Off| 00000000:02:00.0 Off |                  N/A |\n",
            "|  0%   49C    P8               24W / 370W|      3MiB / 24576MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|    0   N/A  N/A      1726      G   /usr/libexec/Xorg                             9MiB |\n",
            "|    0   N/A  N/A      1892      G   /usr/bin/gnome-shell                          3MiB |\n",
            "|    0   N/A  N/A     60940      C   /usr/bin/python                            1026MiB |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "¿Cómo podemos usar una GPU? Fácil, creando una variable indicando `\"cuda\"` en `torch.device`. Esta variable la usaremos para indicar dónde queremos ejecutar las operaciones. Por seguridad, en caso de no tener GPU, podemos asignar `\"cpu\"`, y el código siguiente seguiría siendo válido, aunque más lento.\n",
        "\n",
        "Es posible que estemos en un servidor con varias GPUs, en tal caso podemos elegir solo una GPU. Para ello, hay dos formas:\n",
        "* Indicando `\"cuda:X\"` en `torch.device`, con X el id del dispositivo (por defecto, X es 0). Es decir, si quieres elegir la segunda GPU, indica `\"cuda:1\"`.\n",
        "* Definiendo la variable entorno `CUDA_VISIBLE_DEVICES` con el id de la GPU a usar. Por ejemplo, para usar solo la segunda GPU, ejecutar: \n",
        "```bash\n",
        "export CUDA_VISIBLE_DEVICES=\"1\"\n",
        "```\n",
        "\n",
        "Por ahora usaremos solo la GPU por defecto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # por defecto GPU 0\n",
        "#device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\") # elegir la GPU 1, si la hay\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lo primero a tener en cuenta a la hora de usar una GPU, es que éste dispositivo solo tiene acceso a su propia memoria. Esto quiere decir que todo dato que queremos que toque la GPU, se lo tenemos que enviar. En concreto, demos enviar a la GPU tanto el modelo (sus parámetros deben estar allí para ser operados) como cada batch de datos. Debemos tener en cuenta una serie de restricciones:\n",
        "* Las GPUs tienen una **memoria limitada**, que va desde los 8GB a los 80GB. Si usamos una GPU de gama baja, es posible que tengamos 8GB, esto significa que debemos llevar cuidado con el tamaño de batch que le enviemos. Por eso es importante trabajar con batch de datos, en vez de con el dataset al completo, ya que éste no suele caber al completo en una GPU.\n",
        "* Este flujo de datos hacia y desde la GPU suele ser el mayor **cuello de botella**, por lo que hay que limitarlo al máximo.\n",
        "\n",
        "A continuación verás cómo podemos enviar datos a la GPU. Los tensores cambiarán de estado y pasarán a ser tensores residentes en la GPU. Hay que tener precaución al usarlos, ya que siempre que queramos operar con ellos, necesitaremos hacerlo con otros tensores que también estén en la GPU. Si pedimos operar con un tensor residente en la CPU y un tensor residente en la GPU, la operación fallará."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x0 = train_dataset[0][0] # La X del primer ejemplo\n",
        "print(x0.device)  # este tensor está en la CPU\n",
        "\n",
        "x0_gpu = x0.cuda() # lo copiamos a la GPU\n",
        "x0_gpu.device   # este nuevo tensor está en la GPU\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Hay otra forma de copiar datos a la GPU, más robusta y flexible, es la que verás abajo. Se basa en la variable device, de esta forma:\n",
        "* Si no tienes GPU, device será la CPU, por lo que el código será redundante pero no fallará.\n",
        "* Esta función permite copiar los datos a una GPU que no sea la 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "x0_gpu2 = x0.to(device)\n",
        "print(x0_gpu2.device)\n",
        "# como no vamos a usar esta variable, es una buena práctica\n",
        "# eliminarla para liberar memoria \n",
        "del(x0_gpu2) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vamos a crear de nuevo un modelo, con la configuración anterior. \n",
        "\n",
        "**Ejercicio:** Cambia el siguente FIXME con la misma secuencia de capas del modelo anterior. Esta vez, por simplicidad, puedes definir todas las capas juntas, sin separar por bloque convolucional y clasificador."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_gpu = nn.Sequential( FIXME )\n",
        "model_gpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (1): ReLU()\n",
              "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (4): ReLU()\n",
              "  (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (6): Flatten(start_dim=1, end_dim=-1)\n",
              "  (7): Linear(in_features=1600, out_features=128, bias=True)\n",
              "  (8): ReLU()\n",
              "  (9): Linear(in_features=128, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Solución\n",
        "model_gpu = nn.Sequential(        \n",
        "    nn.Conv2d(1, 32, kernel_size=3),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(kernel_size=2, stride=2), \n",
        "    nn.Conv2d(32, 64, kernel_size=3),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(64 * 5 * 5, 128),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(128, 10)\n",
        "    )\n",
        "model_gpu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ahora, podemos copiar el modelo a la GPU. La operación se hace \"in-place\" para los modelos, es decir, todo el modelo pasa a estar residente en la GPU. Por último, creamos el optimizador en la GPU, que se hará así porque los parámetros están allí."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_gpu.to(device)  # copiamos el modelo al dispositivo (GPU) elegido\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_gpu = optim.Adam(model_gpu.parameters(), lr=0.001) # asignamos los parámetros al optimizador"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Y por último, redefinimos los bucles de entrenamiento y validación. En este caso vamos a cambiarle el nombre para no confundirlos con la versión para CPU, así podemos usar el modelo nuevo en la GPU, así como el optimizador correspondiente. \n",
        "\n",
        "**Ejercicio**: En la línea donde copiamos los datos a la GPU, ¿por qué hay que copiar también `y`?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Train Loss: 0.1916, Val Accuracy: 0.98\n",
            "Epoch [2/5], Train Loss: 0.0558, Val Accuracy: 0.98\n",
            "Epoch [3/5], Train Loss: 0.0379, Val Accuracy: 0.99\n",
            "Epoch [4/5], Train Loss: 0.0272, Val Accuracy: 0.99\n",
            "Epoch [5/5], Train Loss: 0.0216, Val Accuracy: 0.99\n",
            "CPU times: user 38.9 s, sys: 88.1 ms, total: 39 s\n",
            "Wall time: 38.4 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "num_epochs = 5\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model_gpu.train() # Poner el modelo en modo de entrenamiento\n",
        "    loss_acum = 0\n",
        "    for x, y in train_loader: \n",
        "        # Copiar datos a la GPU\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)       \n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model_gpu(x)\n",
        "        loss = criterion(outputs, y)\n",
        "        \n",
        "        # Backward y optimizar\n",
        "        optimizer_gpu.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer_gpu.step()\n",
        "        \n",
        "        loss_acum += loss.item()\n",
        "    \n",
        "    train_loss = loss_acum / len(train_loader)\n",
        "    \n",
        "    # Evaluar el modelo en datos de prueba para obtener la precisión\n",
        "    model_gpu.eval() # Poner el modelo en modo de evaluación        \n",
        "    accu_acum = 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in test_loader:\n",
        "            # Copiar datos a la GPU\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)       \n",
        "\n",
        "            outputs = model_gpu(x)\n",
        "            accu_acum += accuracy(outputs,y)            \n",
        "\n",
        "    accu = accu_acum / len(test_loader)\n",
        "    \n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Val Accuracy: {accu:.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*Solución:* la función de pérdida necesita comparar `y` con las predicciones del modelo `outputs`. Como el modelo está en la GPU, `outputs` es un tensor en la GPU. Por tanto, esta comparación requiere que, o bien `y` y `outputs` estén en el mismo dispositivo. Como la GPU suele ser más rápido en cálculo tensorial, podeos aprovechar que `outputs` está allí, y tan solo copiamos `y`. Además, `y` es un tensor más pequeño y su transferencia es más rápida (recuerda, es un vector de enteros). Alternativamente, podríamos haber copiado `outputs` a la CPU, pero habría sido algo más lento.\n",
        "\n",
        "¿Cuánto de rápido ha ido en comparación con la CPU? Esto se suele medir como la aceleración (sin unidades, tan solo poniendo una *x* al final), dividiendo el tiempo más lento entre el más rápido. En este caso, tiempo en CPU / tiempo en GPU. ¿Qué aceleración obtienes? En mi caso, como verás, en CPU tardó 1 minuto y 13,9 segundos, y en la GPU 38,4 segundos, esto hace aproximadamente 73,9/38,4 = 1,92x más rápido. Aunque es una pequeña aceleración (92% más rápido), esto es debido a que el tamaño de la red es pequeña y no merece mucho la pena utilizar la GPU. Recuerda que usar la GPU conyeva una también copiar datos a la GPU, lo cual suele ser el principal cuello de botella. Cuanto mayor sea el modelo, mayor será el impacto la GPU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Desde la versión 2 de PyTorch, es posible optimizar el modelo para que su manejo sea más eficiente. Esto se hace de forma automática, y se consigue con [`compile`](https://pytorch.org/tutorials/intermediate/torch_compile_tutorial.html).\n",
        "\n",
        "*Atención: Si estás trabajando con un entorno local, y obtienes errores más adelante a la hora de usar el modelo, puede ser que sea por compilar el modelo. Y es que la compilación genera código C++, por lo que debes tener instalado en local el paquete build-essential y python-dev*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#model = torch.compile(model)\n",
        "#model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsI4E-T5WPEz"
      },
      "source": [
        "## 2. Ejercicio\n",
        "\n",
        "Prueba a repetir el proceso con otro conjunto de datos similar, como es [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist), un dataset que pretende reemplazar MNIST como datos para analizar algoritmos de Machine Learning.\n",
        "\n",
        "![fashion-mnist](https://github.com/zalandoresearch/fashion-mnist/raw/master/doc/img/fashion-mnist-sprite.png)\n",
        "\n",
        "## 3. Conclusiones\n",
        "\n",
        "* Con redes convolucionales, podemos emplear capas bidimensionales para poder tratar con imágenes de forma natural, sin tener que aplanarlas, donde se pierde información.\n",
        "* Requiere usar una capa flattern (aplanado) para poder pasar de la parte convolucional a la fully connected."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "name": "Practica5.1. Introducción CNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
