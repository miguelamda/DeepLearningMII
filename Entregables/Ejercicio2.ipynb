{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/miguelamda/DeepLearningMII/blob/main/Entregables/Ejercicio2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkHEHL9WLDeu"
      },
      "source": [
        "# EJERCICIO 2. ENTRENAMIENTO DE MODELOS DE CLASIFICACIÓN PARA DETECTAR MASCARILLAS\n",
        "\n",
        "En este segundo ejercicio tendrás que probar las técnicas que has visto hasta el módulo 5, incluyendo regularización (L2, dropout, data augmentation, etc.), capas convolucionales, pooling, densas, etc. con **al menos 4 configuraciones** distintas. Además, emplearás tu modelo con tu webcam.\n",
        "\n",
        "Para ello, vas a tener que trabajar con un conjunto de datos sobre imágenes de personas que llevan o no máscara.\n",
        "\n",
        "![mask](https://github.com/miguelamda/DeepLearningMII/blob/main/Entregables/img/mask.jpg?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ec_TFbA5LAs-"
      },
      "source": [
        "## 1. Enunciado\n",
        "\n",
        "Empleando el dataset de mascarillas (ver apartado 3), debes construir y probar **al menos 4** configuraciones de modelos con PyTorch que sean sustancialmente distintas. Primero, debes hacer cuatro variantes:\n",
        "1. Dos variantes de **redes convolucionales entrenadas desde cero**. Aquí tendrás que definir (al menos) dos redes con distinta arquitectura, incluyendo: capas convolucionales, pooling, batch normalization, dropout, clasificador (lineal), etc. Simplemente prueba una red menos profunda (menos capas) pero más ancha (más neuronas por capa), y después una red más profunda (más capas) pero menos ancha (menos neuronas por capa). Razona brevemente por qué has considerado cada configuración, y qué esperas conseguir. Considera también el hardware al que tienes acceso, para probar redes más o menos grandes.\n",
        "2. Dos variantes basadas en **redes convolucionales pre-entrenadas** con transfer learning. Diseña (al menos) dos modelos que usen dos modelos pre-entrenados distintos de TorchVision: uno grande de más de 10M de parámetros (VGG, ResNet, DenseNet, ConvNext, etc.) y uno pequeño de menos de 10M de parámetros (MobileNet, EfficientNet, MNASNet, etc.). Haz extracción de características primero, y luego fine tuning, con cada uno de ellos.\n",
        "\n",
        "Además, para todas las configuraciones:\n",
        "\n",
        "* Controla el número de épocas de cada uno usando **early stopping**.\n",
        "* Usa alguna técnica de **regularización**. Al menos prueba una vez (en alguna configuración) el dropout, L2 y/o el batch normalization.\n",
        "* Haz **aumentado de datos** en todas las configuraciones. Razona las transformaciones aplicadas, ¿por qué son válidas para este dataset?\n",
        "* Puedes fijar el optimizador para las cuatro combinaciones, pero juega con el factor de aprendizaje (podría ser distinto para según qué modelo).\n",
        "* Visualiza con gráficas cómo evoluciona el loss y el accuracy. Se valorará el uso de otras métricas como el precision, el recall o el AUC.\n",
        "\n",
        "Detalla cada configuración (arquitectura de red, hiperparámetros, etc), haz un resumen de la arquitectura con **torchsummary**. Después, entrénalas con los datos leídos y analiza los resultados, haciendo una comparativa y razonando lo obtenido.\n",
        "\n",
        "Finalmente, **elige** la mejor configuración a tu criterio, y prepara el **despliegue con PyTorch o con ONNXRuntime**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFfMGuPz4VDN"
      },
      "source": [
        "## 2. Entrega\n",
        "\n",
        "La entrega de este ejercicio se realiza a través de la tarea creada para tal efecto en Enseñanza Virtual. Tienes que entregar un **notebook**, y el **HTML** generado a partir de él, cuyas celdas estén ya evaluadas.\n",
        "\n",
        "La estructura del notebook debe contener los siguientes apartados:\n",
        "\n",
        "0. Cabecera: nombre y apellidos.\n",
        "1. Dataset: descripción, carga y visualización.\n",
        "2. Preparación de los datos para ser usados en PyTorch.\n",
        "3. Modelos y configuraciones creados en PyTorch (un sub-apartado para cada uno, explicando de forma razonada, con tus palabras y figuras, la arquitectura probada). Entrenamiento y evaluación de cada modelo dentro de su sub-apartado para cada uno.\n",
        "4. Análisis de resultados.\n",
        "5. Elección del mejor modelo y despliegue con PyTorch o con ONNXRuntime para predecir las imágenes capturadas con la webcam (ver sección 4). Si no tienes webcam, puedes usar fotos de Internet.\n",
        "6. Bibliografía utilizada (enlaces web, material de clase, libros, etc.)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPR7zuh34VDO"
      },
      "source": [
        "### 2.1. Nota importante\n",
        "-----\n",
        "**HONESTIDAD ACADÉMICA Y COPIAS: un trabajo práctico es un examen, por lo que\n",
        "debe realizarse de manera individual. La discusión y el intercambio de\n",
        "información de carácter general con los compañeros se permite (e incluso se\n",
        "recomienda), pero NO AL NIVEL DE CÓDIGO. Igualmente el remitir código de\n",
        "terceros, OBTENIDO A TRAVÉS DE LA RED o cualquier otro medio, se considerará\n",
        "plagio.**\n",
        "\n",
        "**Cualquier plagio o compartición de código que se detecte significará\n",
        "automáticamente la calificación de CERO EN LA ASIGNATURA para TODOS los\n",
        "alumnos involucrados. Por tanto a estos alumnos NO se les conservará, para\n",
        "futuras convocatorias, ninguna nota que hubiesen obtenido hasta el momento.\n",
        "SIN PERJUICIO DE OTRAS MEDIDAS DE CARÁCTER DISCIPLINARIO QUE SE PUDIERAN\n",
        "TOMAR.**\n",
        "\n",
        "-----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaZbFh0Z4VDP"
      },
      "source": [
        "## 3. El Dataset: Mask Dataset <a class=\"anchor\" id=\"transferdata\"></a>\n",
        "\n",
        "Este pequeño dataset está disponible en Kaggle. Es una versión reducida del construido en [este tutorial](https://www.pyimagesearch.com/2020/05/04/covid-19-face-mask-detector-with-opencv-keras-tensorflow-and-deep-learning/). La pandemia originada por el SARS-Cov2 propició la creación de diversos datasets para detectar si las personas están llevando mascarilla o no. En este dataset para este ejeercicio, tenemos imágenes de personas con y sin mascarilla (algunas se les ha puesto la mascarilla de forma \"artificial\"). El enlace al dataset es el siguiente [Face Mask Detection](https://www.kaggle.com/omkargurav/face-mask-dataset). Si no tienes cuenta en Kaggle, o si quieres ir más rápido, puedes descargarlo en el siguiente [enlace](https://hdvirtual.us.es/discovirt/index.php/s/dijNRMPYfybYd3N/download)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVgYi9OE84W7"
      },
      "source": [
        "## 4. Despliegue del modelo pre-entrenado\n",
        "\n",
        "Una vez hayas entrenado un modelo, puedes lanzar una de las siguientes celdas para hacer la prueba con tu WebCam. No es necesario que adjuntes capturas tuyas, pero sí que se valorará que hagas varias pruebas y analices el ratio de aciertos de tu modelo. Puedes usar también imágenes de internet.\n",
        "\n",
        "### 4.1 Capturando la WebCam desde Google Colab\n",
        "\n",
        "Lanza las siguientes dos celdas para capturar una foto con tu web cam, si estás en Google Colab. Haz clic en el botón \"Capture\" (guardará la imagen en `image.jpg`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zjTIFhFO4VDS"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "def take_photo(filename='image.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return filename"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fz9tTGju4VDS",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image\n",
        "try:\n",
        "  filename = take_photo()\n",
        "  print('Saved to {}'.format(filename))\n",
        "\n",
        "  # Show the image which was just taken.\n",
        "  display(Image(filename))\n",
        "except Exception as err:\n",
        "  # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "  # grant the page permission to access it.\n",
        "  print(str(err))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEFejbor4VDT"
      },
      "source": [
        "## 4.2 Capturando la WebCam desde local\n",
        "\n",
        "El siguiente código debería permitirte capturar una foto desde tu webcam si estás en local en un navegador web."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TYxG6-re4VDT"
      },
      "outputs": [],
      "source": [
        "from IPython.display import HTML, display, update_display\n",
        "\n",
        "main_text = \"\"\"\n",
        "<video id=\"video\" width=\"320\" height=\"240\" autoplay style=\"display:none\"></video>\n",
        "<canvas id=\"canvas\" width=\"320\" height=\"240\"  ></canvas>\n",
        "\n",
        "<script>\n",
        "// Grab elements, create settings, etc.\n",
        "var video = document.getElementById('video');\n",
        "\n",
        "// Get access to the camera!\n",
        "if(navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {\n",
        "    // Not adding `{ audio: true }` since we only want video now\n",
        "    navigator.mediaDevices.getUserMedia({ video: true }).then(function(stream) {\n",
        "        //video.src = window.URL.createObjectURL(stream);\n",
        "        //video.play();\n",
        "        video.srcObject=stream;\n",
        "        video.play();\n",
        "    });\n",
        "}\n",
        "\n",
        "// Elements for taking the snapshot\n",
        "var canvas = document.getElementById('canvas');\n",
        "var context = canvas.getContext('2d');\n",
        "var video = document.getElementById('video');\n",
        "\n",
        "\n",
        "// Trigger photo take\n",
        "\n",
        "setInterval(function() {\n",
        "    context.drawImage(video, 0, 0, 320, 240);\n",
        "    var myCanvas = document.getElementById('canvas');\n",
        "    var image = myCanvas.toDataURL(\"image/png\");\n",
        "    IPython.notebook.kernel.execute(\"image = '\" + image + \"'\")\n",
        "\n",
        "}, 2);\n",
        "\n",
        "</script>\n",
        "\n",
        "\"\"\"\n",
        "HTML(main_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rf2PRtjJ4VDT"
      },
      "source": [
        "## 4.3 Evaluando el modelo\n",
        "\n",
        "La siguiente celda debería permitirte cargar la imagen capturada anteriormente por la webcam. Úsala para hacer inferencia con el modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zvc5fq8G4VDT",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import base64\n",
        "from numpy import asarray\n",
        "import io\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "IMAGE_SIZE = FIXME # el tamaño de imagen que hayas empleado\n",
        "\n",
        "#pil_im = Image.open(io.BytesIO(base64.b64decode(image.split(',')[1]))) # versión en local\n",
        "pil_im = Image.open(filename)  # versión en google colab\n",
        "pil_im = pil_im.convert('RGB')\n",
        "pil_im = pil_im.resize(IMAGE_SIZE, Image.ANTIALIAS)\n",
        "pil_im"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Ejercicio 2: Entrenamiento de Modelos de Clasificación para Detección de Mascarillas",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "nbTranslate": {
      "displayLangs": [
        "*"
      ],
      "hotkey": "alt-t",
      "langInMainMenu": true,
      "sourceLang": "en",
      "targetLang": "fr",
      "useGoogleTranslate": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}