{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/miguelamda/DL/blob/master/3.%20Frameworks%20Software/Practica3.3.%20Keras%3A%20un%20primer%20ejemplo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLqQD-DPhtsF"
      },
      "source": [
        "# PRÁCTICA 3.2. CLASIFICACIÓN MULTICLASE Y USO DE GPU\n",
        "\n",
        "En la práctica anterior vimos como trabajar de forma básica con tensores de PyTorch para entrenar un modelo lineal sobre el dataset MNIST. En esta práctica vamos a ver una forma sencilla de cargar datos pre-definidos y de crear modelos secuenciales (por capas) en PyTorch. Por último, veremos cómo hacer uso de un acelerador, como la GPU. Para ello, usaremos una serie de módulos y clases que son muy útiles para crear y entrenar redes neuronales en PyTorch: [torch.nn](https://pytorch.org/docs/stable/nn.html), [torch.optim](https://pytorch.org/docs/stable/optim.html), [Dataset](https://pytorch.org/docs/stable/data.html?highlight=dataset#torch.utils.data.Dataset) y [DataLoader](https://pytorch.org/docs/stable/data.html?highlight=dataloader#torch.utils.data.DataLoader). Iremos construyendo sobre estas partes, poco a poco, para ver qué hace cada una. Primero, carguemos `torch.nn`, `Dataset` y `DataLoader`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nxo-Fcn4htsF",
        "outputId": "7aca70a1-dce6-414d-fc3a-f240c432efb9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiaeYdKShtsH"
      },
      "source": [
        "## 1. Preparación de los datos\n",
        "\n",
        "### 1.1. Descarga de los datos \n",
        "\n",
        "Volveremos a trabajar con [MNIST](http://yann.lecun.com/exdb/mnist/), pero esta vez con los datos ya pre-procesados dentro de PyTorch. Este entorno tiene varias extensiones para trabajar con problemas de *visión* [torchvision](https://docs.pytorch.org/vision/stable/index.html), *audio* [torchaudio](https://docs.pytorch.org/audio/stable/index.html) y *texto* [torchtext](https://docs.pytorch.org/text/stable/index.html), entre otros. En nuestro caso, vamos a cargar MNIST desde la colección de [datasets de torchvision](https://docs.pytorch.org/vision/stable/datasets.html).\n",
        "\n",
        "Para poder cargar los datos que trae de ejemplo torchvision hay que seguir dos pasos:\n",
        " * primero, cargar la librería torchvision que porporciona las herramientas para trabajar con el dataset concreto (que suelen estar en el paquete `torchvision.datasets`, en este caso llamado `MNIST`); y,\n",
        " * segundo, ejecutar el proceso de carga de los datos para el conjunto de entrenamiento y para el de test. Como es la primera vez que realizamos este proceso concreto, debemos indicar que queremos descargar los datos, ya que, debido a su tamaño, no se instalan por defecto junto con la librería:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "E72OkBzIhtsH"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "\n",
        "train_data = torchvision.datasets.MNIST(\"./data/\", train=True, download=True)\n",
        "valid_data = torchvision.datasets.MNIST(\"./data/\", train=False, download=True)\n",
        "\n",
        "# posiblemente veas abajo varios intentos de descarga"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzfThvqDhtsH"
      },
      "source": [
        "Podemos explorar un poco cómo son cada una de estas variables:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSLMtxuZhtsH",
        "outputId": "88b04f20-83c4-4142-80f4-e6c07ad4e750"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: ./data/\n",
              "    Split: Train"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tenemos para hacer entrenamiento un subconjunto de 60.000 imágenes. El conjunto de test, descargado así porque hemos dicho que `train=False`, lo usaremos para hacer validación, y como vemos abajo, tiene 10.000 imágenes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 10000\n",
              "    Root location: ./data/\n",
              "    Split: Test"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "valid_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(valid_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'PIL.Image.Image'>\n",
            "<class 'int'>\n",
            "la clase es  5\n",
            "el ejemplo es:\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABAElEQVR4nGNgGMyAWUhIqK5jvdSy/9/rGRgYGFhgEnJsVjYCwQwMDAxPJgV+vniQgYGBgREqZ7iXH8r6l/SV4dn7m8gmCt3++/fv37/Htn3/iMW+gDnZf/+e5WbQnoXNNXyMs/5GoQoxwVmf/n9kSGFiwAW49/11wynJoPzx4YIcRlyygR/+/i2XxCWru+vv32nSuGQFYv/83Y3b4p9/fzpAmSyoMnohpiwM1w5h06Q+5enfv39/bcMiJVF09+/fv39P+mFKiTtd/fv3799jgZiBJLT69t+/f/8eDuDEkDJf8+jv379/v7Ryo4qzMDAwMAQGMjBc3/y35wM2V1IfAABFF16Aa0wAOwAAAABJRU5ErkJggg==",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x0, y0 = train_data[0]\n",
        "print(type(x0))\n",
        "print(type(y0))\n",
        "print('la clase es ', y0)\n",
        "print('el ejemplo es:')\n",
        "x0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Habrás notado que las variables que contienen los conjuntos de train y valid no son tensores, sino unos objetos que contienen información de los datos (incluso la ruta donde está almacenado el dataset). En este caso, los datasets que podemos descargar de *torchvision* son subclases de `Dataset`. \n",
        "\n",
        "Un **Dataset** puede ser cualquier clase que tenga predefinida los métodos `__getitem__` y `__len__`. Es por ello que hemos podido ejecutar sin problema las dos celdas anteriores. \n",
        "\n",
        "### 1.2. Adaptación de los datos \n",
        "\n",
        "Verás en la celda de código anterior que el valor X del ejemplo que hemos consultado es directamente una imagen, no un tensor. Y es de tipo entero, lo cual nos sirve para entrenamiento. Por tanto, si queremos recibir un tensor cada vez que indexemos el dataset, debemos transformarlo a tensor. Esto lo podemos hacer con una función que trae TorchVision para convertir de [imágenes PIL](https://pillow.readthedocs.io/en/stable/reference/Image.html) a tensores con la clase [ToTensor](https://pytorch.org/vision/main/generated/torchvision.transforms.ToTensor.html). Puedes ver más transformaciones en la [web](https://pytorch.org/vision/stable/transforms.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# importamos las librerías de transformaciones\n",
        "import torchvision.transforms.v2 as transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,  18,\n",
              "           18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,   0,   0],\n",
              "         [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170, 253,\n",
              "          253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,   0,   0],\n",
              "         [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253, 253,\n",
              "          253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,   0,   0],\n",
              "         [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253, 253,\n",
              "          198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "         [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253, 205,\n",
              "           11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,  90,\n",
              "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253, 190,\n",
              "            2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190, 253,\n",
              "           70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35, 241,\n",
              "          225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  81,\n",
              "          240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "            0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "            0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,   0,   0],\n",
              "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,   0,   0],\n",
              "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39, 148,\n",
              "          229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221, 253,\n",
              "          253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "         [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253, 253,\n",
              "          253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "         [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253, 195,\n",
              "           80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "         [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,  11,\n",
              "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "         [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,   0,\n",
              "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]]],\n",
              "       dtype=torch.uint8)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transforms.PILToTensor()(x0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Bien, hemos convertido cada imagen a un tensor, sin embargo, los valores son enteros entre 0 y 255 (escala de grises). Estos valores, aunque numéricos, no son buenos para introducirlos en una red. Valores tan altos producirán más bien ruido, y afectando negativamente al entrenamiento (los valores de entrada se utilizarán para actualizar los pesos!). Es mejor que los valores estén en un rango entre 0 y 1, por lo que conviene normalizarlos. Esto lo podemos hacer con otra transformación, `ToDtype`. TorchVision nos provee un mecanismo sencillo para crear transformaciones que consiste en la concatenación de otras transformaciones, simplemente usando `Compose`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([28, 28])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0118, 0.0706, 0.0706, 0.0706, 0.4941, 0.5333,\n",
              "         0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1176,\n",
              "         0.1412, 0.3686, 0.6039, 0.6667, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
              "         0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922, 0.9333,\n",
              "         0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9843,\n",
              "         0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.8588,\n",
              "         0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137, 0.9686, 0.9451,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3137,\n",
              "         0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000, 0.1686, 0.6039,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.1373, 0.9451, 0.8824, 0.6275, 0.4235, 0.0039,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9412, 0.9922, 0.9922, 0.4667,\n",
              "         0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7294, 0.9922, 0.9922,\n",
              "         0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627, 0.3647, 0.9882,\n",
              "         0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9765,\n",
              "         0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098, 0.7176, 0.9922,\n",
              "         0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922, 0.9922, 0.9922,\n",
              "         0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922, 0.9922, 0.7882,\n",
              "         0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0902,\n",
              "         0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.3176, 0.0078,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706, 0.8588,\n",
              "         0.9922, 0.9922, 0.9922, 0.9922, 0.7647, 0.3137, 0.0353, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922, 0.9922,\n",
              "         0.9922, 0.9922, 0.9569, 0.5216, 0.0431, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922, 0.8314,\n",
              "         0.5294, 0.5176, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000]])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transf = transforms.Compose([transforms.PILToTensor(), transforms.ToDtype(torch.float32, scale=True)])\n",
        "\n",
        "x0_transformado = transf(x0)[0] # solo la primera imagen\n",
        "print(x0_transformado.shape) # tamaño de la imagen\n",
        "x0_transformado "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Hay muchas formas de aplicar transformaciones a un dataset. Quizás la más sencilla es asignar la transformación al miembro `transform` del objeto del dataset. Esto hará que cada vez que se acceda a un elemento del dataset, éste se devolverá después de aplicarle la transformación aportada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpIRifZghtsH",
        "outputId": "5d3624f5-11df-4405-f73c-4aeda9e52c9b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data.transform = transf\n",
        "valid_data.transform = transf\n",
        "\n",
        "type(train_data[0][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Aunque el objeto dataset (`train_data`, `valid_data`) sea iterable, necesitamos otro mecanismo para muestrear los ejemplos (en batches, de forma aleatoria, etc.). Para ello, podemos usar la clase [DataLoader](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html#preparing-your-data-for-training-with-dataloaders). \n",
        "\n",
        "En el siguiente ejemplo, vamos a definir un tamaño de batch de 64, considerado un buen valor al ser potencia de 2 (así cómo también lo son 8, 16, 32 o 64), y no haremos recorrido aleatorio en validación ya que no lo usaremos para entrenar el modelo en sí. Con esto ya tenemos los datos listos para pasárselos a un modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch = 64\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=batch, shuffle=True)\n",
        "valid_loader = DataLoader(valid_data, batch_size=batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnQsXl8vhtsH"
      },
      "source": [
        "## 2. Definición del modelo\n",
        "\n",
        "Ya estamos en condiciones de definir una red neuronal que consumirá los datos anteriores para ver si somos capaces de dar una primera solución al problema. Como solo estamos haciendo una primera aproximación a PyTorch, la red definida será básica que incluirá los siguientes cuatro elementos:\n",
        "\n",
        "1. Un capa para aplanar ([Flatten](https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html)) los tensores n-dimensionales a vectores (1 dimensión).\n",
        "2. La capa de entrada (784 neuronas)\n",
        "3. Una capa oculta de 512 neuronas con función de activación ReLu\n",
        "4. Una capa de salida (10 neuronas)\n",
        "\n",
        "Esta vez vamos a usar un mecanismo en PyTorch que nos permitirá crear modelos secuenciales (apilación de una capa tras otra) de forma sencilla a partir de una lista. Además, esta librería nos provee de objetos que representan tipos de capas. Todo esto está incluido en la librería `torch.nn`.\n",
        "\n",
        "Pero antes, vamos a ir añadiendo cada componente poco a poco:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "layers = []  #lista vacía"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Primero, recuerda que cada ejemplo es un tensor de (28,28), es decir, de dos dimensiones. Una red perceptrón multicapa (MLP de las siglas en inglés) requiere conectar cada elemento con todas las neuronas de la siguiente capa. Es por ello que necesitamos que la entrada sea un vector, y esto lo conseguimos con `torch.nn.flatten`. En la práctica anterior no hizo falta ya que los datos ya venían en vectores de 1 dimensión de tamaño 728."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "layers.append(nn.Flatten())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ahora, añadamos una capa oculta. Como vimos en la práctica anterior, una capa MLP es simplemente una combinación lineal. Esto ya lo tenemos disponible en `torch.nn.linear`. Esta capa requiere que le indiquemos:\n",
        "* el número de entradas: el número de neuronas en la capa anterior. En nuestro ejemplo, la capa de entrada, 784.\n",
        "* el número de salidas: el número de neuronas de la capa que estamos representando (ya que cada neurona participa en la salida). En nuestro caso, al ser la capa oculta, 512."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "layers.append(nn.Linear(784,512))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La capa anterior no tiene asignada una función de activación. Debemos definirla como otra \"capa\" después de la anterior. En nuestro caso ReLU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "layers.append(nn.ReLU())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para la capa de salida vamos a introducir una capa MLP, sin definir una función de activación.\n",
        "\n",
        "**Ejercicio:** Añade una capa MLP para la capa de salida."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ejercicio\n",
        "layers.append(nn.Linear(FIXME,FIXME))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Solución\n",
        "layers.append(nn.Linear(512,10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Flatten(start_dim=1, end_dim=-1),\n",
              " Linear(in_features=784, out_features=512, bias=True),\n",
              " ReLU(),\n",
              " Linear(in_features=512, out_features=10, bias=True)]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# En resumen tenemos:\n",
        "layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Por ahora solo tenemos una lista de capas. Construyamos un modelo  con [nn.sequential](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html), el cual espera una secuencia de argumentos, por lo que podeomos usar el [operador *](https://docs.python.org/3/reference/expressions.html#expression-lists) para desempaquetar una lista."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Flatten(start_dim=1, end_dim=-1)\n",
              "  (1): Linear(in_features=784, out_features=512, bias=True)\n",
              "  (2): ReLU()\n",
              "  (3): Linear(in_features=512, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = nn.Sequential(*layers)\n",
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Desde la versión 2 de PyTorch, es posible optimizar el modelo para que su manejo sea más eficiente. Esto se hace de forma automática, y se consigue con [`compile`](https://pytorch.org/tutorials/intermediate/torch_compile_tutorial.html).\n",
        "\n",
        "*Atención: Si estás trabajando con un entorno local, y obtienes errores más adelante a la hora de usar el modelo, puede ser que sea por compilar el modelo. Y es que la compilación genera código C++, por lo que debes tener instalado en local el paquete build-essential y python-dev*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OptimizedModule(\n",
              "  (_orig_mod): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=784, out_features=512, bias=True)\n",
              "    (2): ReLU()\n",
              "    (3): Linear(in_features=512, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = torch.compile(model)\n",
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Proceso de entrenamiento\n",
        "\n",
        "Vamos a definir las partes necesarias para realizar el entrenamiento. \n",
        "\n",
        "### 3.1. Función de pérdida, optimizador y métrica"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Cuando trabajamos con problemas de clasificación multiclase, la elección de la función de pérdida es crucial. En PyTorch, dos de las opciones más comunes son [`NLLLoss`]((https://pytorch.org/docs/stable/generated/torch.nn.NLLLoss.html)) (Negative Log Likelihood Loss, la que implementamos a mano en la práctica anterior) y [`CrossEntropyLoss`]((https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)).\n",
        "\n",
        "`NLLLoss` se utiliza cuando la salida de nuestra red neuronal ya ha pasado por una función de activación como **LogSoftmax**. Sin embargo, la práctica estándar y preferida es usar `CrossEntropyLoss`. La principal diferencia es que **`CrossEntropyLoss` realiza la operación de `LogSoftmax` internamente y luego emplea `NLLLoss`**, lo que elimina la necesidad de aplicarla explícitamente a la capa de salida de nuestra red. Esto significa que, en lugar de alimentar a la función de pérdida con probabilidades, le proporcionamos directamente los **logits** (las salidas sin procesar de la última capa de la red). Esta forma de trabajar tiene sus ventajas:\n",
        "\n",
        "* **Eficiencia y estabilidad numérica**: La combinación de las operaciones de `log` y `softmax` en una sola función optimizada (como `LogSoftmax`) es mucho más estable y eficiente desde el punto de vista computacional. Esto previene problemas numéricos como el *underflow* que pueden ocurrir al calcular el logaritmo de valores muy pequeños.\n",
        "\n",
        "* **Simplificación del flujo de trabajo**: Al no tener que añadir una capa de `Softmax` al final de la red, nuestro código se vuelve más limpio y fácil de manejar. La función de pérdida se encarga de la parte matemática del cálculo de la probabilidad.\n",
        "\n",
        "* **Predicción (`Inference`)**: Un punto clave es que para hacer una predicción final (una vez que el modelo está entrenado), no necesitamos la función `softmax`. Para determinar la clase predicha, simplemente necesitamos encontrar el índice del valor más alto en el vector de *logits*. La función **`argmax`** se encarga de esto, ya que el orden de los valores de los logits es el mismo que el de las probabilidades después de aplicar `softmax`. Esto se debe a que `softmax` es una función **monotónica**, por lo que preserva el orden de las entradas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss_func = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ahora, definimos el optimizador para actualizar los parámetros de nuestro modelo. PyTorch ya tiene muchos predefinidos en [torch.optim](https://docs.pytorch.org/docs/stable/optim.html), por lo que no hace falta implementar la regla de actualización de los pesos a mano, como hicimos en la práctica. En concreto, vamos a usar `RMSProp`. A estos optimizadores le tenemos pasar los parámetros del modelo a la hora de definirlos, y también le podemos pasar otros hiperparámetros como el learning rate. Por el momento dejaremos estos valores por defecto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.optim import RMSprop\n",
        "\n",
        "optimizer = RMSprop(model.parameters())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Y por último, vamos a usar como métrica el accuracy, ya que la función de pérdida no estan tan interpetable por humanos. Como antes, la tenemos que definir a mano, ya que PyTorch no la provee."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "def accuracy(out, yb):\n",
        "    # la predicción es la clase del valor más alto\n",
        "    # como tenemos un batch, hay que aplicarlo a través de la dimensión de cada ejemplo\n",
        "    preds = torch.argmax(out, dim=1)  \n",
        "    return (preds == yb).float().mean().item()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 Bucle de entrenamiento\n",
        "\n",
        "El siguiente código muestra cómo queda el bucle de entrenamiento y el de validación con estos nuevos elementos de PyTorch.\n",
        "\n",
        "**Ejercicio**. Observa el código y comprueba las diferencias con respecto a lo que hicimos en la práctica anterior. Después del código podrás ver un resumen de las diferencias principales."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train():\n",
        "    lossAcum = 0\n",
        "    accuAcum = 0\n",
        "    n = len(train_loader.dataset)  # tamaño del dataset\n",
        "    steps = (n - 1) // batch + 1  # número de iteraciones en una época\n",
        "\n",
        "    model.train()              # ponemos al modelo en modo train\n",
        "    for x, y in train_loader:  # iteramos sobre el dataset\n",
        "        optimizer.zero_grad()  # reseteo gradientes\n",
        "        pred = model(x)        # forward pass        \n",
        "        batch_loss = loss_func(pred, y)   # función de pérdida      \n",
        "        batch_loss.backward()  # backward pass\n",
        "        optimizer.step()       # actualización de los pesos\n",
        "\n",
        "        lossAcum += batch_loss.item()\n",
        "        accuAcum += accuracy(pred, y)\n",
        "\n",
        "    print('Entrenamiento - Loss: {:.4f} Accuracy: {:.4f}'.format(lossAcum/steps, accuAcum/steps))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def validate():\n",
        "    lossAcum = 0\n",
        "    accuAcum = 0\n",
        "    n = len(valid_loader.dataset)  # tamaño del dataset\n",
        "    steps = (n - 1) // batch + 1   # número de iteraciones en una época\n",
        "\n",
        "    model.eval()                   # ponemos al modelo en modo train\n",
        "    with torch.no_grad():          # no trackeamos los gradientes a continuación\n",
        "        for x, y in valid_loader:  # iteramos el dataset\n",
        "            pred = model(x)      # inferencia del modelo sobre x\n",
        "\n",
        "            lossAcum += loss_func(pred, y).item()\n",
        "            accuAcum += accuracy(pred, y)\n",
        "    print('Validación - Loss: {:.4f} Accuracy: {:.4f}'.format(lossAcum/steps, accuAcum/steps))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "¿Puedes ver las diferencias con respecto al bucle de la práctica anterior?\n",
        "* Los modelos creados con `torch.nn` tienen dos modos para trabajar, en modo *train* y en modo *eval*. Ciertas capas, como las de normalización y las de dropout, se comportan de forma distinta cuando están siendo entrenadas a cuando se usan para inferencia, y estos modos las prepara para cada ocasión.\n",
        "* El recorrido de los batches se hace mucho más sencillo con `DataLoader`, quedando en tan solo un bucle con iteradores x e y. Ya hemos definido previamente el tipo de recorrido, tamaño de batch, y las transformaciones aplicadas a los datos.\n",
        "* Tenemos un objeto `optimizer` usado en `train()` para actualizar los pesos. Este objeto calcula los gradientes aplicados a cada parámetro del modelo (recuerda que se los pasamos cuando lo creamos). Sin embargo, PyTorch permite acumular los gradientes de batch a otro, para permitir configuraciones avanzadas, por lo que para nuestro caso más simple, debemos resetear los gradientes en cada batch (recuerda: el gradiente lo calculamos para cada batch, y es el que se usa para hacer la actualización de pesos). Después de retropropagar los gradientes, podemos dar un paso (`step`), es decir, actualizar los parámetros.\n",
        "\n",
        "Finalmente, tenemos el bucle de entrenamiento, que quedaría igual que antes. Esta vez vamos a hacer tan solo dos épocas, y hemos añadido en la primera línea una función mágica de Jupyter que nos permite medir el tiempo de ejecución de toda la celda. Podrás ver que la ejecución de la celda tarda bastante, por supuesto dependiendo de la velocidad de tu CPU. Si has hecho al menos una época pero ha tardado mucho, te aconsejo parar la ejecución de la celda."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:  0\n",
            "Entrenamiento - Loss: 0.6151 Accuracy: 0.9225\n",
            "Validación - Loss: 0.1695 Accuracy: 0.9499\n",
            "Epoch:  1\n",
            "Entrenamiento - Loss: 0.1473 Accuracy: 0.9595\n",
            "Validación - Loss: 0.1623 Accuracy: 0.9585\n",
            "CPU times: user 1h 9min 25s, sys: 1.24 s, total: 1h 9min 26s\n",
            "Wall time: 10min 6s\n"
          ]
        }
      ],
      "source": [
        "%%time \n",
        "\n",
        "epochs = 2\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print('Epoch: ', epoch)\n",
        "    train()\n",
        "    validate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Debemos tener en cuenta que los valores mostrados son el error y métricas calculados sobre los propios datos de entrenamiento. Sin embargo, como el objetivo de un modelo de aprendizaje es generalizar bien sobre datos que el proceso de entrenamiento no ha visto anteriormente, necesitamos el conjunto de test para evaluar cómo se comporta la red sobre ejemplos que no ha usado para ajustarse.\n",
        "\n",
        "Sobre los datos de entrenamiento alcanzamos rápidamente una precisión de 0.989 (i.e. 98.9%), pero veamos cómo de bien se comporta con los datos de test (que no se han usado para aprender):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Recuerda que tan solo hemos añadido una capa oculta con respecto al modelo de la práctica anterior, lo cual ha incrementado 51 veces en complejidad. El modelo lineal tenía $784*10 = 7.840$ parámetros, mientras que ahora tenemos $784*512 + 512*10 = 406.528$. Además, usamos un optimizador más complejo, y recorremos el dataset de forma aleatoria."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Aceleración con GPUs\n",
        "\n",
        "Según tu CPU, el bucle de entrenamiento anterior pudo haber tardado más o menos, pero seguro que ha durado varios minutos. Y es que, por mucho que hayamos optimizado el modelo, una CPU no es el dispositivo más eficiente para ser usado en el entrenamiento de redes neuronales. La CPU está diseñada para realizar cómputo con instrucciones muy complejas, pero con un nivel de paralelismo limitado (¿cuántos núcleos tiene tu CPU?). En cambio, una **tarjeta gráfica (GPU)** sí que provee la potencia computacional para acelerar los cálculos requeridos. Estamos hablando, principalmente, de **multiplicaciones de matrices** (como la que hicimos en la práctica anterior), y esta operación se puede *paralelizar* muy bien (piensa en calcular, en paralelo, el valor de cada elemento de salida). Una GPU provee de miles de núcleos que pueden, fácilmente, repartirse la carga de trabajo a través de su memoria. Si tienes una GPU de *NVIDIA*, podrás hacer estos cálculos con **CUDA**. Si tienes una GPU de *AMD*, como *ROCm*. Hay otros dispositivos, como las *TPUs* de Google, pero no las usaremos en esta asignatura. Si tienes acceso a una TPU, puedes configurarla también con PyTorch, simplemente busca la ayuda en el manual.\n",
        "\n",
        "Esta parte de la práctica podrás ejecutarla sin problema una vez estés en un entorno con una GPU (bien sea en local o en la nube). En la siguiente celda ejecutaremos la instrucción que nos muestra las GPUs disponibles en el sistema: `nvidia-smi`. Éste es un programa que se instala junto al driver de CUDA, la plataforma para cálculo paralelo de NVIDIA. La exclamación al comienzo indica que el código no es Python, sino una instrucción a ejecutar en el sistema (p.ej. en la terminal)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mon Sep 15 09:51:55 2025       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 530.30.02              Driver Version: 530.30.02    CUDA Version: 12.1     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                  Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA GeForce RTX 2080         Off| 00000000:01:00.0 Off |                  N/A |\n",
            "|  0%   43C    P8                3W / 265W|     18MiB /  8192MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "|   1  NVIDIA GeForce RTX 3090         Off| 00000000:02:00.0 Off |                  N/A |\n",
            "|  0%   44C    P8               21W / 370W|      3MiB / 24576MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|    0   N/A  N/A      1915      G   /usr/libexec/Xorg                             9MiB |\n",
            "|    0   N/A  N/A      2081      G   /usr/bin/gnome-shell                          3MiB |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A continuación, podemos escoger la GPU que queremos emplear. Esto se utiliza eligiendo `\"cuda\"` en `torch.device`. Por seguridad, en caso de no tener GPU, podemos asignar CPU, y el código siguiente seguiría siendo válido, aunque mucho más lento.\n",
        "\n",
        "En caso de tener más de una GPU, podemos elegir otra indicando `\"cuda:X\"` con X el id del dispositivo (por defecto, X es 0). Es decir, si quieres elegir la segunda GPU, indica `\"cuda:1\"`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # por defecto GPU 0\n",
        "#device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\") # elegir la GPU 1\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lo primero a tener en cuenta a la hora de usar una GPU, es que éste dispositivo solo tiene acceso a su propia memoria. Esto quiere decir que todo dato que queremos que toque la GPU, se lo tenemos que enviar. En concreto, demos enviar a la GPU tanto el modelo (sus parámetros deben estar allí para ser operados) como cada batch de datos. Debemos tener en cuenta una serie de restricciones:\n",
        "* Las GPUs tienen una **memoria limitada**, que va desde los 8GB a los 80GB. Si usamos una GPU de gama baja, es posible que tengamos 8GB, esto significa que debemos llevar cuidado con el tamaño de batch que le enviemos. Por eso es importante trabajar con batch de datos, en vez de con el dataset al completo, ya que éste no suele caber al completo en una GPU.\n",
        "* Este flujo de datos hacia y desde la GPU suele ser el mayor **cuello de botella**, por lo que hay que limitarlo al máximo.\n",
        "\n",
        "A continuación verás cómo podemos enviar datos a la GPU. Los tensores cambiarán de estado y pasarán a ser tensores residentes en la GPU. Hay que tener precaución al usarlos, ya que siempre que queramos operar con ellos, necesitaremos hacerlo con otros tensores que también estén en la GPU. Si pedimos operar con un tensor residente en la CPU y un tensor residente en la GPU, la operación fallará."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(x0_transformado.device)  # este tensor está en la CPU\n",
        "\n",
        "x0_gpu = x0_transformado.cuda() # lo copiamos a la GPU\n",
        "x0_gpu.device   # este nuevo tensor está en la GPU\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Hay otra forma de copiar datos a la GPU, más robusta y flexible, es la que verás abajo. Se basa en la variable device, de esta forma:\n",
        "* Si no tienes GPU, device será la CPU, por lo que el código será redundante pero no fallará.\n",
        "* Esta función permite copiar los datos a una GPU que no sea la 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "x0_gpu2 = x0_transformado.to(device)\n",
        "print(x0_gpu2.device)\n",
        "# como no vamos a usar esta variable, es una buena práctica\n",
        "# eliminarla para liberar memoria \n",
        "del(x0_gpu2) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vamos a crear de nuevo un modelo, con la configuración anterior. \n",
        "\n",
        "**Ejercicio:** ¿qué debemos escribir para crear un nuevo modelo secuencial?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_gpu = FIXME(*layers)\n",
        "model_gpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Flatten(start_dim=1, end_dim=-1)\n",
              "  (1): Linear(in_features=784, out_features=512, bias=True)\n",
              "  (2): ReLU()\n",
              "  (3): Linear(in_features=512, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Solución\n",
        "model_gpu = nn.Sequential(*layers)\n",
        "model_gpu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ahora, podemos copiar el modelo a la GPU. La operación se hace \"in-place\" para los modelos, es decir, todo el modelo pasa a estar residente en la GPU. Aprovechamos también para compilar el modelo, que esta vez se hará la compilación para la GPU. Por último, creamos el optimizador en la GPU, que se hará así porque los parámetros están allí."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_gpu.to(device)  # copiamos el modelo al dispositivo (GPU) elegido\n",
        "model_gpu = torch.compile(model_gpu)  # compilamos el modelo para ese dispositivo\n",
        "optimizer_gpu = RMSprop(model_gpu.parameters()) # asignamos los parámetros al optimizador"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Y por último, redefinimos los bucles de entrenamiento y validación. En este caso vamos a cambiarle el nombre para no confundirlos con la versión para CPU, así podemos usar el modelo nuevo en la GPU, así como el optimizador correspondiente. \n",
        "\n",
        "**Ejercicio**: En la línea donde copiamos los datos a la GPU, ¿por qué hay que copiar también `y`?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_gpu():\n",
        "    lossAcum = 0\n",
        "    accuAcum = 0\n",
        "    n = len(train_loader.dataset)  # tamaño del dataset\n",
        "    steps = (n - 1) // batch + 1   # número de iteraciones en una época\n",
        "\n",
        "    model_gpu.train()              # ponemos al modelo en modo train\n",
        "    for x, y in train_loader:      # iteramos sobre el dataset (CPU)\n",
        "        x_gpu, y_gpu = x.to(device), y.to(device) # Copiar datos a la GPU\n",
        "        optimizer_gpu.zero_grad()  # reseteo gradientes\n",
        "        pred = model_gpu(x_gpu)    # forward pass        \n",
        "        batch_loss = loss_func(pred, y_gpu)   # función de pérdida      \n",
        "        batch_loss.backward()      # backward pass\n",
        "        optimizer_gpu.step()       # actualización de los pesos\n",
        "\n",
        "        lossAcum += batch_loss.item()\n",
        "        accuAcum += accuracy(pred, y_gpu)\n",
        "\n",
        "    print('Entrenamiento - Loss: {:.4f} Accuracy: {:.4f}'.format(lossAcum/steps, accuAcum/steps))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def validate_gpu():\n",
        "    lossAcum = 0\n",
        "    accuAcum = 0\n",
        "    n = len(valid_loader.dataset)  # tamaño del dataset\n",
        "    steps = (n - 1) // batch + 1   # número de iteraciones en una época\n",
        "\n",
        "    model_gpu.eval()               # ponemos al modelo en modo train\n",
        "    with torch.no_grad():          # no trackeamos los gradientes a continuación\n",
        "        for x, y in valid_loader:  # iteramos el dataset (CPU)\n",
        "            x_gpu, y_gpu = x.to(device), y.to(device) # copiamos datos a la GPU\n",
        "            pred = model_gpu(x_gpu)  # hacemos inferencia en la GPU\n",
        "\n",
        "            lossAcum += loss_func(pred, y_gpu).item()\n",
        "            accuAcum += accuracy(pred, y_gpu)\n",
        "    print('Validación - Loss: {:.4f} Accuracy: {:.4f}'.format(lossAcum/steps, accuAcum/steps))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*Solución:* la función de pérdida necesita comparar `y` con las predicciones del modelo `pred`. Como el modelo está en la GPU, `pred` es un tensor en la GPU. Por tanto, esta comparación requiere que, o bien `y` y `pred` estén en el mismo dispositivo. Como la GPU suele ser más rápido en cálculo tensorial, podeos aprovechar que `pred` está allí, y tan solo copiamos `y`. Además, `y` es un tensor más pequeño y su transferencia es más rápida (recuerda, es un vector de enteros). Alternativamente, podríamos haber copiado `pred` a la CPU, pero habría sido algo más lento.\n",
        "\n",
        "Hora de realizar el entrenamiento. ¿Cuánto de rápido ha ido en comparación con la CPU? Esto se suele medir como la aceleración (sin unidades, tan solo poniendo una *x* al final), dividiendo el tiempo más lento entre el más rápido. En este caso, tiempo en CPU / tiempo en GPU. ¿Qué aceleración obtienes? En mi caso, como verás, en CPU tardó 10 minutos y 6 segundos, y en la GPU 46,2 segundos, esto hace aproximadamente 606/46,2 = 13,12x más rápido."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0\n",
            "Entrenamiento - Loss: 0.5698 Accuracy: 0.9270\n",
            "Validación - Loss: 0.1377 Accuracy: 0.9628\n",
            "Epoch: 1\n",
            "Entrenamiento - Loss: 0.1443 Accuracy: 0.9600\n",
            "Validación - Loss: 0.1825 Accuracy: 0.9552\n",
            "Epoch: 2\n",
            "Entrenamiento - Loss: 0.1196 Accuracy: 0.9694\n",
            "Validación - Loss: 0.1565 Accuracy: 0.9668\n",
            "Epoch: 3\n",
            "Entrenamiento - Loss: 0.1080 Accuracy: 0.9726\n",
            "Validación - Loss: 0.2865 Accuracy: 0.9510\n",
            "Epoch: 4\n",
            "Entrenamiento - Loss: 0.0967 Accuracy: 0.9771\n",
            "Validación - Loss: 0.1584 Accuracy: 0.9710\n",
            "CPU times: user 43.9 s, sys: 572 ms, total: 44.5 s\n",
            "Wall time: 46.2 s\n"
          ]
        }
      ],
      "source": [
        "%%time \n",
        "\n",
        "epochs = 5\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print('Epoch: {}'.format(epoch))\n",
        "    train_gpu()\n",
        "    validate_gpu()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-p3HioushtsI"
      },
      "source": [
        "Lo normal es que la red se comporte peor en los datos de /validación que en los datos de entrenamiento, ya que el proceso de entrenamiento consiste precisamente en ajustar los pesos para que el error cometido en estos últimos se minimice. Esta diferencia de comportamiento entre entrenamiento y test se denomina **overfitting** (o **sobreajuste**). En todo caso, con una red tan simple como la que hemos usado se alcanzan cotas de casi el 98% de aciertos.\n",
        "\n",
        "Finalmente, podemos ver las predicciones que hace la red sobre algunos datos del conjunto de test, y comprobamos cómo de acertado está según la etiqueta real. Puedes jugar con `i` para ver el resultado con otro ejemplo del conjunto de test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x,y = valid_data[1]\n",
        "image = transforms.ToPILImage()(x)\n",
        "plt.imshow(image, cmap='gray')\n",
        "\n",
        "pred = model_gpu(x.to(device))\n",
        "pred.argmax(1).item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "kT1aR5WMnR8c",
        "outputId": "b53de6fd-26c3-4a3c-d2d9-a2ea4665b0e4"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def muestra_imagen_prediccion(i):\n",
        "    # obtenemos datos del dataset en posición i\n",
        "    x,y = valid_data[i]\n",
        "    # transformamos a imagen\n",
        "    image = transforms.ToPILImage()(x)\n",
        "    # mostramos la imagen en grande\n",
        "    plt.imshow(image, cmap='gray')   \n",
        "    plt.show() \n",
        "    # mostrar la etiqueta \n",
        "    print(\"Etiqueta numérica:   \", y)\n",
        "    # hacemos inferencia\n",
        "    pred = model_gpu(x.to(device))\n",
        "    print(\"Predicción:          \", pred.argmax(1).item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Etiqueta numérica:    7\n",
            "Predicción:           7\n"
          ]
        }
      ],
      "source": [
        "x = 60 # prueba aquí otro número para ver otro ejemplo\n",
        "muestra_imagen_prediccion(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZStMoAx8nrk1"
      },
      "source": [
        "Puedes usar el siguiente código para ver `k` ejemplos mal predichos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XjovP4YvnpXq",
        "outputId": "3f5b7dda-1826-4ed1-83e5-5f189784ee1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Elemento:             18\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Etiqueta numérica:    3\n",
            "Predicción:           5\n",
            "----------------------\n",
            "Elemento:             151\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Etiqueta numérica:    9\n",
            "Predicción:           5\n",
            "----------------------\n",
            "Elemento:             193\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Etiqueta numérica:    9\n",
            "Predicción:           8\n",
            "----------------------\n",
            "Elemento:             241\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAbaklEQVR4nO3df2xV9f3H8dct0Ctqe1mp7e2VAgUEnPxYxqRr1A6loa0LASVGlCVojAQsZoo/lm4TlG2pw+Qr0TFdooO5iT9IBkSzkWm1JbqCASXEqR3FutbQFiXpvaVIYe3n+wfxzist5Vzu7fu2fT6ST9J7znnf8/bjSV+ce28/1+eccwIAYIClWTcAABieCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYGGndwLf19PToyJEjysjIkM/ns24HAOCRc04dHR0KhUJKS+v7PiflAujIkSPKz8+3bgMAcIGam5s1bty4Pven3EtwGRkZ1i0AABKgv9/nSQugTZs2aeLEibroootUWFio995777zqeNkNAIaG/n6fJyWAXnnlFa1Zs0br1q3T+++/r9mzZ6u0tFRHjx5NxukAAIORS4K5c+e6ioqK6OPu7m4XCoVcVVVVv7XhcNhJYjAYDMYgH+Fw+Jy/7xN+B3Tq1Cnt379fJSUl0W1paWkqKSlRXV3dWcd3dXUpEonEDADA0JfwAPryyy/V3d2t3NzcmO25ublqbW096/iqqioFAoHo4BNwADA8mH8KrrKyUuFwODqam5utWwIADICE/x1Qdna2RowYoba2tpjtbW1tCgaDZx3v9/vl9/sT3QYAIMUl/A4oPT1dc+bMUXV1dXRbT0+PqqurVVRUlOjTAQAGqaSshLBmzRotX75cP/jBDzR37lxt3LhRnZ2duvPOO5NxOgDAIJSUALr11lv1xRdfaO3atWptbdX3vvc97dq166wPJgAAhi+fc85ZN/FNkUhEgUDAug0AwAUKh8PKzMzsc7/5p+AAAMMTAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMjrRsA+hMKhTzXrFq1Kq5z3XbbbZ5rJk+eHNe5vNq8ebPnmurq6rjO9eqrr3quOX36dFznwvDFHRAAwAQBBAAwkfAAevTRR+Xz+WLG9OnTE30aAMAgl5T3gK666iq9+eab/zvJSN5qAgDESkoyjBw5UsFgMBlPDQAYIpLyHtChQ4cUCoU0adIkLVu2TE1NTX0e29XVpUgkEjMAAENfwgOosLBQW7Zs0a5du/TMM8+osbFR1113nTo6Ono9vqqqSoFAIDry8/MT3RIAIAUlPIDKy8t1yy23aNasWSotLdXf/vY3tbe39/l3BZWVlQqHw9HR3Nyc6JYAACko6Z8OGDNmjKZOnaqGhoZe9/v9fvn9/mS3AQBIMUn/O6Djx4/r8OHDysvLS/apAACDSMID6MEHH1Rtba0+++wz/fOf/9RNN92kESNGxLXECQBg6Er4S3Cff/65brvtNh07dkyXXXaZrr32Wu3Zs0eXXXZZok8FABjEfM45Z93EN0UiEQUCAes2cB7S0rzfQN9+++2ea37xi194rpk2bZrnGvzPJ5984rmmpKTEc82RI0c812DwCIfDyszM7HM/a8EBAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwwWKkiNuKFSs81zz77LNJ6ORsfX0FfH9eeOEFzzV9fdliok2ZMsVzzcqVK+M614gRIzzX9PWtx+eybNkyzzXd3d2ea2CDxUgBACmJAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCC1bChpUuXxlW3du1azzXTp0/3XPPvf//bc01ZWZnnGkn67LPP4qpLVbfccktcdRs3bvRck5eX57lm4sSJnmuampo818AGq2EDAFISAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEyOtG4C94uLiuOriWVi0ra3Nc82NN97ouWaoLSoar23btsVVF89Cs/EsRorhjTsgAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJliMFAPqz3/+s+eaTz/9NAmdALDGHRAAwAQBBAAw4TmAdu/erYULFyoUCsnn82nHjh0x+51zWrt2rfLy8jR69GiVlJTo0KFDieoXADBEeA6gzs5OzZ49W5s2bep1/4YNG/TUU0/p2Wef1d69e3XJJZeotLRUJ0+evOBmAQBDh+cPIZSXl6u8vLzXfc45bdy4Ub/85S+1aNEiSdILL7yg3Nxc7dixQ0uXLr2wbgEAQ0ZC3wNqbGxUa2urSkpKotsCgYAKCwtVV1fXa01XV5cikUjMAAAMfQkNoNbWVklSbm5uzPbc3Nzovm+rqqpSIBCIjvz8/ES2BABIUeafgqusrFQ4HI6O5uZm65YAAAMgoQEUDAYlSW1tbTHb29raovu+ze/3KzMzM2YAAIa+hAZQQUGBgsGgqquro9sikYj27t2roqKiRJ4KADDIef4U3PHjx9XQ0BB93NjYqAMHDigrK0vjx4/Xfffdp1//+te64oorVFBQoEceeUShUEiLFy9OZN8AgEHOcwDt27dP119/ffTxmjVrJEnLly/Xli1b9PDDD6uzs1MrVqxQe3u7rr32Wu3atUsXXXRR4roGAAx6ngNo3rx5cs71ud/n82n9+vVav379BTWGoamlpcW6BZyH7du3e6656qqrPNcsWbLEc82TTz7puQapyfxTcACA4YkAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYMLzatjAhVi5cqXnGlY/HnjxrGwdj+9+97sDch6kJu6AAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmGAxUgyoUCjkuaa4uNhzze7duz3X4H+mTp1q3QKGAe6AAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmGAxUuiPf/xjXHWLFy/2XBMMBj3X/O53vxuQGkmqr6+Pq86rgoICzzXLli1LQie9mzhx4oCcJ57rIT093XPNqVOnPNcg+bgDAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYMLnnHPWTXxTJBJRIBCwbgPnobKy0nPNb37zmyR0guEkFAp5rmltbU1CJ+hPOBxWZmZmn/u5AwIAmCCAAAAmPAfQ7t27tXDhQoVCIfl8Pu3YsSNm/x133CGfzxczysrKEtUvAGCI8BxAnZ2dmj17tjZt2tTnMWVlZWppaYmOl1566YKaBAAMPZ6/EbW8vFzl5eXnPMbv98f1TYcAgOEjKe8B1dTUKCcnR9OmTdOqVat07NixPo/t6upSJBKJGQCAoS/hAVRWVqYXXnhB1dXV+u1vf6va2lqVl5eru7u71+OrqqoUCASiIz8/P9EtAQBSkOeX4PqzdOnS6M8zZ87UrFmzNHnyZNXU1Gj+/PlnHV9ZWak1a9ZEH0ciEUIIAIaBpH8Me9KkScrOzlZDQ0Ov+/1+vzIzM2MGAGDoS3oAff755zp27Jjy8vKSfSoAwCDi+SW448ePx9zNNDY26sCBA8rKylJWVpYee+wxLVmyRMFgUIcPH9bDDz+sKVOmqLS0NKGNAwAGN88BtG/fPl1//fXRx1+/f7N8+XI988wzOnjwoP70pz+pvb1doVBICxYs0K9+9Sv5/f7EdQ0AGPRYjBRxi+cfFTfccIPnmnvuucdzzRVXXOG5RpIOHTrkuaawsDCuc3m1d+9ezzXPPfdcXOeaOXOm55r169fHdS6vWIx08GAxUgBASiKAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmEj4V3Jj+Ojq6vJc8/e//31AaoLBoOcaKb5Vk6dMmRLXubzq61uFk2H06NEDdi6vpk+f7rmG1bBTE3dAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATLAYKYakgVx8ciAXCYV05ZVXeq6pqalJfCO4YNwBAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMMFipFBOTk5cde+8847nmp07d3qu2bRpk+eazz77zHMNBoft27dbt4AE4Q4IAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACRYjhY4dOxZX3fPPP++5pqqqynNNRkaG55rHH3/cc43EIqbAQOIOCABgggACAJjwFEBVVVW6+uqrlZGRoZycHC1evFj19fUxx5w8eVIVFRUaO3asLr30Ui1ZskRtbW0JbRoAMPh5CqDa2lpVVFRoz549euONN3T69GktWLBAnZ2d0WPuv/9+vfbaa9q2bZtqa2t15MgR3XzzzQlvHAAwuHn6EMKuXbtiHm/ZskU5OTnav3+/iouLFQ6H9fzzz2vr1q264YYbJEmbN2/WlVdeqT179uiHP/xh4joHAAxqF/QeUDgcliRlZWVJkvbv36/Tp0+rpKQkesz06dM1fvx41dXV9focXV1dikQiMQMAMPTFHUA9PT267777dM0112jGjBmSpNbWVqWnp2vMmDExx+bm5qq1tbXX56mqqlIgEIiO/Pz8eFsCAAwicQdQRUWFPvzwQ7388ssX1EBlZaXC4XB0NDc3X9DzAQAGh7j+EHX16tV6/fXXtXv3bo0bNy66PRgM6tSpU2pvb4+5C2pra1MwGOz1ufx+v/x+fzxtAAAGMU93QM45rV69Wtu3b9dbb72lgoKCmP1z5szRqFGjVF1dHd1WX1+vpqYmFRUVJaZjAMCQ4OkOqKKiQlu3btXOnTuVkZERfV8nEAho9OjRCgQCuuuuu7RmzRplZWUpMzNT9957r4qKivgEHAAghqcAeuaZZyRJ8+bNi9m+efNm3XHHHZKkJ598UmlpaVqyZIm6urpUWlqq3//+9wlpFgAwdPicc866iW+KRCIKBALWbeA8jB071nPNu+++67lm6tSpnms++eQTzzWS9PTTT3uuaWlp8VyzY8cOzzUD6YknnvBc88ADD3iu+fjjjz3XxPNyPn/eYSMcDiszM7PP/awFBwAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwwWrYGFDjx4/3XPOPf/zDc008K2jH67///a/nmo6OjiR0kjjnWsG4LyNGjPBcs2LFCs81zz33nOca2GA1bABASiKAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCxUiR8vLz8z3XrF+/Pq5zLV++PK46SP/6178811x33XWea9rb2z3XwAaLkQIAUhIBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATLEaKIcnn88VVN3LkSM81P/nJTzzXFBQUeK658847Pdd8+umnnmsk6aOPPvJcs3btWs81X3zxhecaDB4sRgoASEkEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMsBgpACApWIwUAJCSCCAAgAlPAVRVVaWrr75aGRkZysnJ0eLFi1VfXx9zzLx58+Tz+WLGypUrE9o0AGDw8xRAtbW1qqio0J49e/TGG2/o9OnTWrBggTo7O2OOu/vuu9XS0hIdGzZsSGjTAIDBz9PXP+7atSvm8ZYtW5STk6P9+/eruLg4uv3iiy9WMBhMTIcAgCHpgt4DCofDkqSsrKyY7S+++KKys7M1Y8YMVVZW6sSJE30+R1dXlyKRSMwAAAwDLk7d3d3uxz/+sbvmmmtitv/hD39wu3btcgcPHnR/+ctf3OWXX+5uuummPp9n3bp1ThKDwWAwhtgIh8PnzJG4A2jlypVuwoQJrrm5+ZzHVVdXO0muoaGh1/0nT5504XA4Opqbm80njcFgMBgXPvoLIE/vAX1t9erVev3117V7926NGzfunMcWFhZKkhoaGjR58uSz9vv9fvn9/njaAAAMYp4CyDmne++9V9u3b1dNTY0KCgr6rTlw4IAkKS8vL64GAQBDk6cAqqio0NatW7Vz505lZGSotbVVkhQIBDR69GgdPnxYW7du1Y033qixY8fq4MGDuv/++1VcXKxZs2Yl5T8AADBIeXnfR328zrd582bnnHNNTU2uuLjYZWVlOb/f76ZMmeIeeuihfl8H/KZwOGz+uiWDwWAwLnz097ufxUgBAEnBYqQAgJREAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADCRcgHknLNuAQCQAP39Pk+5AOro6LBuAQCQAP39Pve5FLvl6Onp0ZEjR5SRkSGfzxezLxKJKD8/X83NzcrMzDTq0B7zcAbzcAbzcAbzcEYqzINzTh0dHQqFQkpL6/s+Z+QA9nRe0tLSNG7cuHMek5mZOawvsK8xD2cwD2cwD2cwD2dYz0MgEOj3mJR7CQ4AMDwQQAAAE4MqgPx+v9atWye/32/diinm4Qzm4Qzm4Qzm4YzBNA8p9yEEAMDwMKjugAAAQwcBBAAwQQABAEwQQAAAE4MmgDZt2qSJEyfqoosuUmFhod577z3rlgbco48+Kp/PFzOmT59u3VbS7d69WwsXLlQoFJLP59OOHTti9jvntHbtWuXl5Wn06NEqKSnRoUOHbJpNov7m4Y477jjr+igrK7NpNkmqqqp09dVXKyMjQzk5OVq8eLHq6+tjjjl58qQqKio0duxYXXrppVqyZIna2tqMOk6O85mHefPmnXU9rFy50qjj3g2KAHrllVe0Zs0arVu3Tu+//75mz56t0tJSHT161Lq1AXfVVVeppaUlOt555x3rlpKus7NTs2fP1qZNm3rdv2HDBj311FN69tlntXfvXl1yySUqLS3VyZMnB7jT5OpvHiSprKws5vp46aWXBrDD5KutrVVFRYX27NmjN954Q6dPn9aCBQvU2dkZPeb+++/Xa6+9pm3btqm2tlZHjhzRzTffbNh14p3PPEjS3XffHXM9bNiwwajjPrhBYO7cua6ioiL6uLu724VCIVdVVWXY1cBbt26dmz17tnUbpiS57du3Rx/39PS4YDDonnjiiei29vZ25/f73UsvvWTQ4cD49jw459zy5cvdokWLTPqxcvToUSfJ1dbWOufO/L8fNWqU27ZtW/SYjz/+2ElydXV1Vm0m3bfnwTnnfvSjH7mf/vSndk2dh5S/Azp16pT279+vkpKS6La0tDSVlJSorq7OsDMbhw4dUigU0qRJk7Rs2TI1NTVZt2SqsbFRra2tMddHIBBQYWHhsLw+ampqlJOTo2nTpmnVqlU6duyYdUtJFQ6HJUlZWVmSpP379+v06dMx18P06dM1fvz4IX09fHsevvbiiy8qOztbM2bMUGVlpU6cOGHRXp9SbjHSb/vyyy/V3d2t3NzcmO25ubn65JNPjLqyUVhYqC1btmjatGlqaWnRY489puuuu04ffvihMjIyrNsz0draKkm9Xh9f7xsuysrKdPPNN6ugoECHDx/Wz3/+c5WXl6uurk4jRoywbi/henp6dN999+maa67RjBkzJJ25HtLT0zVmzJiYY4fy9dDbPEjS7bffrgkTJigUCungwYP62c9+pvr6ev31r3817DZWygcQ/qe8vDz686xZs1RYWKgJEybo1Vdf1V133WXYGVLB0qVLoz/PnDlTs2bN0uTJk1VTU6P58+cbdpYcFRUV+vDDD4fF+6Dn0tc8rFixIvrzzJkzlZeXp/nz5+vw4cOaPHnyQLfZq5R/CS47O1sjRow461MsbW1tCgaDRl2lhjFjxmjq1KlqaGiwbsXM19cA18fZJk2apOzs7CF5faxevVqvv/663n777ZivbwkGgzp16pTa29tjjh+q10Nf89CbwsJCSUqp6yHlAyg9PV1z5sxRdXV1dFtPT4+qq6tVVFRk2Jm948eP6/Dhw8rLy7NuxUxBQYGCwWDM9RGJRLR3795hf318/vnnOnbs2JC6PpxzWr16tbZv36633npLBQUFMfvnzJmjUaNGxVwP9fX1ampqGlLXQ3/z0JsDBw5IUmpdD9afgjgfL7/8svP7/W7Lli3uo48+citWrHBjxoxxra2t1q0NqAceeMDV1NS4xsZG9+6777qSkhKXnZ3tjh49at1aUnV0dLgPPvjAffDBB06S+7//+z/3wQcfuP/85z/OOecef/xxN2bMGLdz50538OBBt2jRIldQUOC++uor484T61zz0NHR4R588EFXV1fnGhsb3Ztvvum+//3vuyuuuMKdPHnSuvWEWbVqlQsEAq6mpsa1tLREx4kTJ6LHrFy50o0fP9699dZbbt++fa6oqMgVFRUZdp14/c1DQ0ODW79+vdu3b59rbGx0O3fudJMmTXLFxcXGnccaFAHknHNPP/20Gz9+vEtPT3dz5851e/bssW5pwN16660uLy/Ppaenu8svv9zdeuutrqGhwbqtpHv77bedpLPG8uXLnXNnPor9yCOPuNzcXOf3+938+fNdfX29bdNJcK55OHHihFuwYIG77LLL3KhRo9yECRPc3XffPeT+kdbbf78kt3nz5ugxX331lbvnnnvcd77zHXfxxRe7m266ybW0tNg1nQT9zUNTU5MrLi52WVlZzu/3uylTpriHHnrIhcNh28a/ha9jAACYSPn3gAAAQxMBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAAT/w8ULOIbR78e/AAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Etiqueta numérica:    9\n",
            "Predicción:           8\n",
            "----------------------\n"
          ]
        }
      ],
      "source": [
        "k=4\n",
        "for i in range(0,len(valid_data)):\n",
        "    x,y = valid_data[i]\n",
        "    pred = model_gpu(x.to(device))\n",
        "    if pred.argmax(1).item() != y:\n",
        "        k=k-1\n",
        "        if k<0:\n",
        "            break;\n",
        "        print (\"Elemento:            \",i)\n",
        "        muestra_imagen_prediccion(i)\n",
        "        print(\"----------------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coWuEWgSn7CA"
      },
      "source": [
        "## 5. Ejercicio Opcional Propuesto\n",
        "\n",
        "Juega con el entrenamiento del modelo para ver qué resultados obtienes y si consigues mejorar (o por el contrario se empeora el resultado): \n",
        "* cambia el método de [optimización](https://docs.pytorch.org/docs/stable/optim.html), \n",
        "* cambia el learning rate\n",
        "* amplía el número de epochs, \n",
        "* añade o quita capas, \n",
        "* cambia las [funciones de activación](https://docs.pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity), \n",
        "* ¿Otra idea?"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "name": "Practica3.3. Keras: un primer ejemplo.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
