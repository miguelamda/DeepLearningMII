{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/miguelamda/DL/blob/master/3.%20Frameworks%20Software/Practica3.6.%20Keras%3A%20regresi%C3%B3n.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wj5m2laQmQmI"
   },
   "source": [
    "# PRÁCTICA 3.4. REGRESIÓN Y K-VALIDACIÓN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qrJZLqPJmQmK"
   },
   "source": [
    "En las prácticas anteriores hemos trabajado con clasificación, tanto multiclase como binaria. Ahora veremos un ejemplo de cómo hacer regresión, intentando predecir un valor continuo en vez de una etiqueta discreta.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "xNfWBMttmQmJ",
    "outputId": "3496d9aa-4a47-4563-82de-be8cbc88f429"
   },
   "outputs": [],
   "source": [
    "# Imports y configuración\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WxXamJfumQmK"
   },
   "source": [
    "## 1. El Dataset de Precios de Casas de Boston\n",
    "\n",
    "Intentaremos predecir el precio medio de **casas de un barrio de Boston** (a partir de datos de los años 70). Para ello, usaremos algo de información asociada a algunas de las casas de ese barrio: tasa de crimen, impuestos locales, etc.\n",
    "\n",
    "A diferencia de los datasets vistos en los ejemplos anteriores, éste es realmente pequeño, apenas 506 anotaciones, que están divididas en 404/102 en entrenamiento/test. Además, cada una de las características de los datos de entrada usa una escala diferente, por ejemlo, algunos valores son proporciones (continuos en $[0,1]$), otros toman valores discretos entre 1 y 12, otros entre 0 y 100, etc.\n",
    "\n",
    "Podemos echar un vistazo a los datos. Para ello vamos a usar la plataforma *OpenML*, la cual es una colaboración en machine learning que permite a los investigadores y científicos de datos compartir y acceder a datasets, algoritmos y resultados de experimentos de forma abierta. La función `fetch_openml` de `scikit-learn` es una interfaz que te permite descargar datasets directamente desde esta plataforma. Como la plataforma OpenML puede estar en mantemiento, o que el dataset se mueva por cuestiones éticas (incluye una características sobre *composición racial*), vamos a poner una opción de respaldo de descarga directa del dataset original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargado Boston desde fetch_openml (sklearn).\n",
      "      CRIM    ZN  INDUS CHAS    NOX     RM   AGE     DIS RAD    TAX  PTRATIO  \\\n",
      "0  0.00632  18.0   2.31    0  0.538  6.575  65.2  4.0900   1  296.0     15.3   \n",
      "1  0.02731   0.0   7.07    0  0.469  6.421  78.9  4.9671   2  242.0     17.8   \n",
      "2  0.02729   0.0   7.07    0  0.469  7.185  61.1  4.9671   2  242.0     17.8   \n",
      "3  0.03237   0.0   2.18    0  0.458  6.998  45.8  6.0622   3  222.0     18.7   \n",
      "4  0.06905   0.0   2.18    0  0.458  7.147  54.2  6.0622   3  222.0     18.7   \n",
      "\n",
      "        B  LSTAT  MEDV  \n",
      "0  396.90   4.98  24.0  \n",
      "1  396.90   9.14  21.6  \n",
      "2  392.83   4.03  34.7  \n",
      "3  394.63   2.94  33.4  \n",
      "4  396.90   5.33  36.2  \n",
      "\n",
      "X shape: (506, 13) y shape: (506,)\n"
     ]
    }
   ],
   "source": [
    "# Carga del dataset Boston Housing\n",
    "# Intentamos varias opciones para mayor robustez:\n",
    "# 1) sklearn.datasets.fetch_openml('boston', version=1)\n",
    "# 2) si no está disponible, descargamos desde la UCI repository\n",
    "\n",
    "def load_boston_dataset():\n",
    "    try:\n",
    "        from sklearn.datasets import fetch_openml\n",
    "        data = fetch_openml(name='boston', version=1, as_frame=True, parser='auto')        \n",
    "        X = data.data.values.astype('float32') # obtenemos el numpy array de las X\n",
    "        y = data.target.values.astype('float32') # numpy array de Y\n",
    "        print('Cargado Boston desde fetch_openml (sklearn).')\n",
    "        return X, y, data.frame\n",
    "    except Exception as e:\n",
    "        print('Falló fetch_openml:', e)\n",
    "        try:  # Si falla openml, podemos ir directo a los datos originales\n",
    "            url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data'\n",
    "            col_names = ['CRIM','ZN','INDUS','CHAS','NOX','RM','AGE','DIS','RAD','TAX','PTRATIO','B','LSTAT','MEDV']\n",
    "            df = pd.read_csv(url, header=None, sep='\\s+', names=col_names)\n",
    "            X = df.iloc[:, :-1].values.astype('float32')\n",
    "            y = df['MEDV'].values.astype('float32')\n",
    "            print('Cargado Boston desde UCI repository (pandas).')\n",
    "            return X, y, df\n",
    "        except Exception as e2:\n",
    "            raise RuntimeError('No se pudo descargar el dataset Boston automáticamente. Por favor descarga los datos manualmente y cárgalos en X, y.') from e2\n",
    "\n",
    "X, y, data = load_boston_dataset()\n",
    "\n",
    "print(data.head())\n",
    "\n",
    "print('\\nX shape:', X.shape, 'y shape:', y.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X3UTT7ozmQmK"
   },
   "source": [
    "\n",
    "Como se puede observar, cada dato tiene 13 características, que esperamos permitan obtener una relación funcional para predecir su precio, como por ejemplo:\n",
    "\n",
    "1. Ratio de crimen per cápita.\n",
    "2. Proporción de área residencial en lotes de 25.000 pies cuadrado.\n",
    "3. ...\n",
    "\n",
    "El objetivo es el valor medio de las casas, en miles de dólares:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24.  21.6 34.7 33.4 36.2 28.7 22.9 27.1 16.5 18.9 15.  18.9 21.7 20.4\n",
      " 18.2 19.9 23.1 17.5 20.2 18.2]\n",
      "Mínimo:  5.0\n",
      "Máximo:  50.0\n"
     ]
    }
   ],
   "source": [
    "print(y[:20]) # veamos los 20 primeros\n",
    "print('Mínimo: ', y.min())\n",
    "print('Máximo: ', y.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-KpnQ4p4mQmK"
   },
   "source": [
    "\n",
    "Los precios están, aproximadamente, entre 5.000\\$ y 50.000\\$ (precios de los años 70, claro). Vamos también a dividir el dataset en train 80% y en test 20%, forzando el random_state para reproducibilidad.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Test shapes: (404, 13) (102, 13)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print('Train/Test shapes:', X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xkS4FIvZmQmK"
   },
   "source": [
    "## 2. Preparando los datos\n",
    "\n",
    "Sería problemático alimentar la red neuronal con los datos en bruto que proporciona el dataset, que hace uso de rangos tan diferentes para cada característica. Si fuera así, la red debería aprender, además de la relación funcional, a adaptar automáticamente la heterogeneidad de los datos, lo que haría que el aprendizaje fuera más complicado. Como vimos en la práctica anterior, una buena práctica de preprocesamiento consiste en hacer una estandarización de cada característica: para cada una de ellas (una columna) se extrae la media de sus valores y se divide por su desviación estándar, de esta forma la nueva características estará centrada en 0 y con desviación estándar 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "AXkNfL_emQmK"
   },
   "outputs": [],
   "source": [
    "# calculamos la media del conjunto de train\n",
    "mean = X_train.mean(axis=0)\n",
    "X_train -= mean\n",
    "# calculamos la desviación estándar del conjunto de train\n",
    "std = X_train.std(axis=0)\n",
    "X_train /= std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto equivale a usar `StandardScaler` de scikit-learn, como hicimos en la práctica anterior, donde aplicamos la estandarización a todo el dataset antes de dividirlo.\n",
    "\n",
    "Sin embargo, al estandarizar el dataset de entrenamiento, el modelo se ajustará para datos cuyos valores se les haya sustraído la media y la desviación del conjunto de entrenamiento. Por tanto, todo dato que después se le pase al modelo para hacer una predicción, debería también ser transformado de la misma manera. Para ilustrarlo, vamos a normalizar el conjunto de test con la media y desviación del conjunto de entrenamiento. Recuerda esta técnica, ya que más adelante tendremos que usarla con modelos convolucionales pre-entrenados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizamos el conjunto de test con la media y std del conjunto de train\n",
    "X_test -= mean\n",
    "X_test /= std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kJmYDR8WmQmK"
   },
   "source": [
    "## 3. Construyendo la red\n",
    "\n",
    "Debido a que hay pocas muestras para el entrenamiento, vamos a usar una red muy pequeña, con solo 2 capas ocultas, cada una de 64 unidades. En general, cuantos menos datos tengamos de entrenamiento, mayor será el sobreajuste, así que usar una red pequeña puede mitigar este efecto porque el número de parámetros en toda la red es más bajo.\n",
    "\n",
    "A continuación vamos a definir un modelo con la siguiente configuración:\n",
    "* Dos capas ocultas lineales con función de activación ReLU, con 64 neuronas cada una.\n",
    "* Una capa de salida sin función de activación. Esta configuración es habitual cuando se hace regresión escalar (de un solo valor), ya que las funciones de activación restringen el rango de la salida; por ejemplo, una `sigmoid` aprende a predecir valores en $[0,1]$ y una `ReLU` pone a 0 los valores negativos, pero una activación lineal puede aprender cualquier valor.\n",
    "\n",
    "**Ejercicio:** Define el modelo propuesto reemplazando los `FIXME`. Esta vez lo vamos a hacer dentro de una función que defina el modelo. Nos será útil para hacer K-validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos las dimensiones de entrada y salida\n",
    "INPUT_FEATURES = X_train.shape[1]\n",
    "\n",
    "def build_model():\n",
    "    # 1) define el modelo\n",
    "    model = nn.FIXME(FIXME)\n",
    "\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "print(\"--- Arquitectura del Modelo ---\")\n",
    "print(model)\n",
    "summary(model,verbose=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Arquitectura del Modelo Secuencial ---\n",
      "Sequential(\n",
      "  (0): Linear(in_features=13, out_features=64, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "├─Linear: 1-1                            896\n",
       "├─ReLU: 1-2                              --\n",
       "├─Linear: 1-3                            4,160\n",
       "├─ReLU: 1-4                              --\n",
       "├─Linear: 1-5                            65\n",
       "=================================================================\n",
       "Total params: 5,121\n",
       "Trainable params: 5,121\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solución\n",
    "# Definimos las dimensiones de entrada y salida\n",
    "INPUT_FEATURES = X_train.shape[1]\n",
    "\n",
    "def build_model():\n",
    "    # --- Arquitectura del modelo con nn.Sequential ---\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(INPUT_FEATURES, 64), # Capa de entrada\n",
    "        nn.ReLU(),                     # Función de activación    \n",
    "        nn.Linear(64, 64),             # Capa oculta\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64, 1) # Capa de salida (produce un logit)\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "print(\"--- Arquitectura del Modelo Secuencial ---\")\n",
    "print(model)\n",
    "summary(model,verbose=0)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T0MH_7ZtmQmK"
   },
   "source": [
    "Usaremos `MSE`, *Mean Squared Error* (error cuadrático medio) como función de pérdida, habitual en el caso de problemas de regresión. Sin embargo, para monitorizar el entrenamiento usamos `mae`, *Mean Absolute Error*, que es el valor absoluto de la diferencia entre las predicciones y los objetivos. Por ejemplo, un MAE de 0,5 en este problema significa que nuestras predicciones difieren en unos 500\\$ de media."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae_numpy(preds, targets):\n",
    "    return np.mean(np.abs(preds - targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t9vKX38ymQmK"
   },
   "source": [
    "## 4. K-validación cruzada\n",
    "\n",
    "En esta práctica, además de hacer regresión, vamos a aplicar una técnica clásica en Machine Learning. Para evaluar la red mientras ajustamos los hiperparámetros (como el número de epochs a usar), podríamos dividir simplemente el conjunto de entrenamiento en entrenamiento y validación, tal y como hicimos en ejemplos anteriores. Sin embargo, debido a que hay muy pocas muestras, el conjunto de validación acabaría siendo muy pequeño (unas 100 muestras), por lo que las métricas de validación podrían depender excesivamente de qué muestras concretas han terminado en cada conjunto, mostrando, posiblemente, una gran varianza.\n",
    "\n",
    "La mejor práctica en este tipo de situaciones es usar una **K-validación cruzada**, que consiste en dividir los datos disponibles en $K$ particiones (normalmente, entre 4 y 5), después instanciar $K$ modelos exactos, entrenar cada uno de los modelos usando $K-1$ de las particiones anteriores y evaluar sobre la restante. La métrica de evaluación será la media de las $K$ métricas obtenidas sobre las validaciones de cada modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función que entrena un modelo sobre datos en formato numpy\n",
    "# Devuelve el modelo entrenado y el historial de la métrica MAE\n",
    "def train(train_data, train_targets, val_data, val_targets, num_epochs, batch_size=1):\n",
    "    # Convertir a tensores y DataLoader \n",
    "    train_dataset = TensorDataset(torch.from_numpy(train_data), torch.from_numpy(train_targets))\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    # Para validación, al ser pequeño, no vamos a crear un dataLoader, ya que lo enviaremos entero\n",
    "    val_tensor = torch.from_numpy(val_data)\n",
    "\n",
    "    # crear modelo nuevo\n",
    "    model = build_model()\n",
    "    # Usaremos RMSProp como optimizador\n",
    "    optimizer = optim.RMSprop(model.parameters(), lr=0.001)\n",
    "    # Función de pérdida, MSE\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    val_mae_history = []\n",
    "    # Bucle de entrenamiento (esta vez en modo silencioso)\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        model.train()\n",
    "        for xb, yb in train_loader:\n",
    "            yb = yb.unsqueeze(1)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(xb)\n",
    "            loss = criterion(outputs, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        # evaluación en validación (sin gradientes)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs_val = model(val_tensor)\n",
    "        val_mae = mae_numpy(outputs_val.squeeze().numpy(), val_targets)\n",
    "        val_mae_history.append(val_mae)\n",
    "        # imprimimos cada 100 épocas para no saturar salida\n",
    "        if epoch % 100 == 0:\n",
    "            print(f' Epoch {epoch} val_mae={val_mae:.4f}')\n",
    "        \n",
    "    return model, val_mae_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-fold: entrenar k modelos y recoger val MAE por época\n",
    "def k_validacion(k,num_epochs):\n",
    "    all_mae_histories = []\n",
    "    num_val_samples = len(X_train) // k\n",
    "    \n",
    "    for i in range(k):\n",
    "        print('\\n-- Procesando Fold #', i)\n",
    "        # preparar particiones: 1 para validación\n",
    "        val_data = X_train[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "        val_targets = y_train[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "\n",
    "        # k-1 para entrenamiento, se quita el de validación\n",
    "        partial_train_data = np.concatenate(\n",
    "            [X_train[:i * num_val_samples], X_train[(i + 1) * num_val_samples:]],\n",
    "            axis=0)\n",
    "        partial_train_targets = np.concatenate(\n",
    "            [y_train[:i * num_val_samples], y_train[(i + 1) * num_val_samples:]],\n",
    "            axis=0)\n",
    "\n",
    "        # Entrenamos un modelo sobre el fold (ver función arriba)\n",
    "        model, val_mae_history = train(partial_train_data,partial_train_targets,val_data,val_targets,num_epochs)\n",
    "        \n",
    "        # El modelo no nos hace falta, podemos liberar memoria    \n",
    "        del(model)\n",
    "        # Guardamos los resultados del entrenamiento\n",
    "        all_mae_histories.append(val_mae_history)\n",
    "    return all_mae_histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- Procesando Fold # 0\n",
      " Epoch 100 val_mae=2.4473\n",
      "\n",
      "-- Procesando Fold # 1\n",
      " Epoch 100 val_mae=2.8233\n",
      "\n",
      "-- Procesando Fold # 2\n",
      " Epoch 100 val_mae=2.5549\n",
      "\n",
      "-- Procesando Fold # 3\n",
      " Epoch 100 val_mae=2.1392\n"
     ]
    }
   ],
   "source": [
    "k = 4\n",
    "num_epochs = 100\n",
    "\n",
    "all_scores = k_validacion(k,num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iIcq4W7WmQmK"
   },
   "source": [
    "\n",
    "Como puedes observar, las posibles métricas de validación varían mucho (dependiendo de la ejecución, de 2,1 a 2,9, puede depender del fold concreto), por lo que la media (2,4) es mucho más fiable que cada una de las otras valoraciones por separado... este es precisamente el valor de la K-validacion cruzada. Todavía estamos con un error significativo de unos `2.400$` en precios que están en un rango de entre `10.000$` y `50.000`, así que intentemos entrenar la red durante un poco más de tiempo: 200 epochs. Con el fin de guardar un registro de cómo de bien funciona el modelo en cada epoch, vamos a modificar el bucle de entrenamiento para almacenar el score de validación en cada epoch. Esto puede tardar unos minutos:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vYsTP_jzmQmL",
    "outputId": "be17fb72-132e-4f47-944d-0cf91c634756"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- Procesando Fold # 0\n",
      " Epoch 100 val_mae=2.1307\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 200\n",
    "all_mae_entrenamientos = k_validacion(k,num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pYoCzD_HmQmL"
   },
   "source": [
    "Ahora podemos calcular la media de los valores MAE en cada epoch:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZJvb5qQWmQmL"
   },
   "outputs": [],
   "source": [
    "average_mae_entrenamiento = [\n",
    "    np.mean([x[i] for x in all_mae_entrenamientos]) for i in range(num_epochs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qs-UH7bNmQmL"
   },
   "source": [
    "Y representarlo:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "8cSo-yjumQmL",
    "outputId": "e41e9cfc-e12a-49ad-f07c-ae3c1abfd8fd"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(1, len(average_mae_entrenamiento) + 1), average_mae_entrenamiento)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validación MAE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ve6nrFnmQmL"
   },
   "source": [
    "\n",
    "Puede ser un poco difícil extraer conocimiento de esta gráfica debido a los problemas de escala que presenta y a la alta varianza, así que podemos hacer lo siguiente:\n",
    "\n",
    "* Omitir los primeros 10 puntos de los datos, que parecen mostrar una escala distinta al resto de la curva.\n",
    "* Reemplazar cada punto con una media exponencial de los puntos anteriores, con el fin de obtener una curva más suave.\n",
    "\n",
    "Probemos esta última opción:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "urFWwmc5mQmL",
    "outputId": "1e41074f-6cdc-4b01-e510-26c97051bf71"
   },
   "outputs": [],
   "source": [
    "def smooth_curve(points, factor=0.9):\n",
    "  smoothed_points = []\n",
    "  for point in points:\n",
    "    if smoothed_points:\n",
    "      previous = smoothed_points[-1]\n",
    "      smoothed_points.append(previous * factor + point * (1 - factor))\n",
    "    else:\n",
    "      smoothed_points.append(point)\n",
    "  return smoothed_points\n",
    "\n",
    "smooth_mae_entrenamiento = smooth_curve(average_mae_entrenamiento[10:])\n",
    "\n",
    "plt.plot(range(1, len(smooth_mae_entrenamiento) + 1), smooth_mae_entrenamiento)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validación MAE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sO18hEW3mQmL"
   },
   "source": [
    "\n",
    "De acuerdo con esta nueva gráfica, parece que el MAE de validación deja de mejorar tras 60-80 epochs (recuerda, cuanto menor valor, mejor), a partir de entonces empieza a haber sobreajuste.\n",
    "\n",
    "Se podría considerar ajustar otros hiperparámetros del modelo (por ejemplo, el tamaño de las capas ocultas), y de analizar la mejor combinación, podemos entrenar una versión final del modelo sobre todos los datos de entrenamiento y medir el rendimiento sobre los datos de test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tBaZ9Z4hmQmL",
    "outputId": "7b051dc2-33dc-4c8b-e13e-cfa1857e2450"
   },
   "outputs": [],
   "source": [
    "# Entrenamos el modelo final con 80 épocas, ya que según la gráfica anterior parece un buen número\n",
    "# Usamos para validación el mismo conjunto de test\n",
    "modelo_final, history = train(X_train, y_train, X_test, y_test, num_epochs=80, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EJERCICIO**: reemplaza los FIXME para poder evaluar el modelo sobre el conjunto de test. Puedes ver la solución debajo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluación en test\n",
    "modelo_final.FIXME() # poner el modelo en modo inferencia\n",
    "with torch.FIXME():  # no registrar los gradientes\n",
    "    preds = modelo_final(torch.from_numpy(FIXME)) # usa el conjunto de test\n",
    "    preds_test = preds.squeeze().FIXME() # convierte a numpy array\n",
    "test_mse = np.mean((preds_test - y_test)**2)\n",
    "test_mae = np.mean(np.abs(preds_test - y_test))\n",
    "print('\\nResultados en test -> MSE: {:.4f}, MAE: {:.4f}'.format(test_mse, test_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IhiG03RsmQmL",
    "jupyter": {
     "source_hidden": true
    },
    "outputId": "3e57d5a9-f64e-4f0a-8c4a-3b8915acea15"
   },
   "outputs": [],
   "source": [
    "# Solución.\n",
    "# Evaluación en test\n",
    "modelo_final.eval()\n",
    "with torch.no_grad():\n",
    "    preds = modelo_final(torch.from_numpy(X_test))\n",
    "    preds_test = preds.squeeze().numpy()\n",
    "test_mse = np.mean((preds_test - y_test)**2)\n",
    "test_mae = np.mean(np.abs(preds_test - y_test))\n",
    "print('\\nResultados en test -> MSE: {:.4f}, MAE: {:.4f}'.format(test_mse, test_mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6x9V4d9WmQmL"
   },
   "source": [
    "Según el resultado en el conjunto de test, se sigue mostrando un error todavía muy alto, rondando los 2.200\\$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tMZcyL2DmQmL"
   },
   "source": [
    "## 5. Conclusiones y referencias\n",
    "\n",
    "* La regresión hace uso de funciones de pérdida distintas a la clasificación. La más común suele ser la *Mean Squared Error* (MSE).\n",
    "* Además, las métricas de evaluación también suelen ser distintas, por ejemplo, *Mean Absolute Error* (MAE). El término \"accuracy\" aquí no tiene sentido.\n",
    "* Cuando las características de los datos de entrada usan diferentes rangos, cada una de ellas ha de ser normalizada/estandarizada independientemente en la etapa de preprocesamiento.\n",
    "* Si has usado estandarización, conserva la media y la desviación para aplicar la transformación en inferencia.\n",
    "* Cuando tenemos pocos datos, usar K-validación cruzada puede ser un buen método para evaluar el modelo de forma más fiable sobre una configuración de hiper-parámetros.\n",
    "* Cuando hay pocos datos, es preferible usar redes pequeñas con pocas capas (normalmente, 1 o 2) con el fin de evitar un sobreajuste exagerado.\n",
    "\n",
    "Referencias:\n",
    "* [Deep Learning with Python](https://deeplearningwithpython.io/chapters/), François Chollet, Matthew Watson"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "Practica3.6. Keras: regresión.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
